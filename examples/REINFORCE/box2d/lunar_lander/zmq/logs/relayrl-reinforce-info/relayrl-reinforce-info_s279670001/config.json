{
    "__class__":	"REINFORCE",
    "act_dim":	4,
    "buf_size":	1000000,
    "config_loader":	"<builtins.ConfigLoader object at 0x10561ae90>",
    "config_path":	"relayrl_config.json",
    "env_dir":	".",
    "exp_name":	"relayrl-reinforce-info",
    "hyperparams":	{
        "discrete":	true,
        "gamma":	0.9800000190734863,
        "lam":	0.9700000286102295,
        "pi_lr":	0.0003000000142492354,
        "seed":	1,
        "train_vf_iters":	80,
        "traj_per_epoch":	8,
        "vf_lr":	0.0010000000474974513,
        "with_vf_baseline":	false
    },
    "log_data_dir":	"././logs/",
    "logger_kwargs":	{
        "exp_name":	"relayrl-reinforce-info",
        "output_dir":	"././logs/relayrl-reinforce-info/relayrl-reinforce-info_s279670001"
    },
    "obs_dim":	8,
    "seed":	279670001,
    "self":	{
        "<REINFORCE.REINFORCE.REINFORCE object at 0x10563fcd0>":	{
            "_discrete":	true,
            "_gamma":	0.9800000190734863,
            "_lam":	0.9700000286102295,
            "_model":	{
                "PolicyWithoutBaseline(\n  (policy): DiscretePolicyNetwork(\n    (pi_network): Sequential(\n      (0): Linear(in_features=8, out_features=128, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=128, out_features=4, bias=True)\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "policy":	{
                            "DiscretePolicyNetwork(\n  (pi_network): Sequential(\n    (0): Linear(in_features=8, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=128, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=128, out_features=4, bias=True)\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "pi_network":	{
                                        "Sequential(\n  (0): Linear(in_features=8, out_features=128, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=128, out_features=128, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=8, out_features=128, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0202,  0.3366, -0.0133, -0.0544,  0.0859,  0.1155,  0.0354,  0.2983,\n         0.1444,  0.1930, -0.3297,  0.0438,  0.2007,  0.0621,  0.1840, -0.1473,\n         0.0123, -0.0091, -0.1914, -0.2155,  0.1469, -0.3433, -0.1309, -0.0076,\n        -0.2790, -0.1367,  0.2647, -0.1974, -0.0803, -0.0572, -0.2620, -0.0549,\n        -0.0468,  0.2793,  0.1670, -0.3063,  0.2274, -0.2572, -0.1864,  0.2038,\n        -0.0910, -0.1179,  0.0107, -0.3371,  0.3311,  0.1388, -0.0518,  0.1777,\n        -0.1350, -0.2220,  0.2843,  0.1792,  0.3208, -0.2198, -0.2283, -0.0254,\n         0.0894, -0.0265,  0.0398, -0.0149, -0.2139, -0.2726, -0.1774, -0.2497,\n        -0.3162, -0.0087, -0.3168, -0.1422,  0.3151,  0.1011, -0.2451, -0.2771,\n         0.0177,  0.2165, -0.2344, -0.1818,  0.2646,  0.2697,  0.1603, -0.0923,\n        -0.0748,  0.2465, -0.0981, -0.0760,  0.1595,  0.1468,  0.3386, -0.3230,\n        -0.1821, -0.2381,  0.3073, -0.2822,  0.0039,  0.2635, -0.1951,  0.2515,\n         0.0315, -0.3137,  0.3186, -0.1614, -0.0782,  0.1205, -0.0468,  0.2799,\n        -0.2670, -0.3166,  0.0215,  0.3222,  0.1971,  0.2061,  0.2195, -0.0547,\n         0.1173,  0.0903,  0.0780, -0.3184,  0.3425,  0.0472,  0.1205, -0.2312,\n        -0.0814,  0.0281,  0.2535, -0.3122, -0.0525, -0.0267,  0.1377, -0.1100],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.2413,  0.1591,  0.2084,  ..., -0.1059, -0.3359,  0.1043],\n        [-0.1823,  0.1796, -0.3137,  ...,  0.2922, -0.2141, -0.3420],\n        [-0.2996, -0.2075, -0.0080,  ...,  0.1062, -0.3055,  0.2452],\n        ...,\n        [ 0.0285,  0.3223, -0.2581,  ..., -0.1472,  0.2594,  0.0720],\n        [-0.0867, -0.2193, -0.1792,  ..., -0.2298, -0.1688,  0.2420],\n        [ 0.2575,  0.3113, -0.0134,  ..., -0.3346,  0.2927,  0.2124]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	128,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=128, out_features=128, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0685, -0.0594, -0.0819,  0.0040,  0.0379,  0.0253,  0.0676,  0.0291,\n        -0.0067, -0.0782,  0.0757, -0.0117,  0.0378, -0.0843, -0.0370,  0.0799,\n         0.0484,  0.0814, -0.0242, -0.0361,  0.0454,  0.0052,  0.0166,  0.0018,\n         0.0105, -0.0003, -0.0097,  0.0340, -0.0384, -0.0298,  0.0113, -0.0551,\n        -0.0224, -0.0473,  0.0189, -0.0629, -0.0578, -0.0306, -0.0315, -0.0583,\n         0.0169, -0.0205,  0.0491, -0.0777, -0.0382,  0.0029, -0.0167,  0.0590,\n         0.0527,  0.0565,  0.0803, -0.0492, -0.0138, -0.0015, -0.0011,  0.0180,\n        -0.0143, -0.0475, -0.0358,  0.0181,  0.0310,  0.0862, -0.0505, -0.0348,\n        -0.0581, -0.0135,  0.0490, -0.0589,  0.0281, -0.0800,  0.0005, -0.0828,\n        -0.0316, -0.0316,  0.0162, -0.0746,  0.0689,  0.0415,  0.0196, -0.0424,\n        -0.0550,  0.0653,  0.0443,  0.0347, -0.0555, -0.0509, -0.0611,  0.0348,\n         0.0872, -0.0823,  0.0882, -0.0729, -0.0868,  0.0011,  0.0321,  0.0209,\n         0.0551,  0.0592, -0.0158,  0.0221, -0.0702,  0.0471,  0.0021, -0.0785,\n         0.0282,  0.0651,  0.0306, -0.0245, -0.0619,  0.0840,  0.0076, -0.0779,\n        -0.0082,  0.0375, -0.0459,  0.0502, -0.0067,  0.0371,  0.0326,  0.0111,\n         0.0880, -0.0129, -0.0636, -0.0408, -0.0102, -0.0133, -0.0787,  0.0277],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0738,  0.0194,  0.0528,  ...,  0.0143, -0.0328, -0.0610],\n        [-0.0182, -0.0763, -0.0569,  ...,  0.0861,  0.0622,  0.0855],\n        [-0.0476, -0.0719, -0.0271,  ...,  0.0085,  0.0746,  0.0477],\n        ...,\n        [ 0.0863, -0.0245, -0.0683,  ..., -0.0055, -0.0505,  0.0606],\n        [ 0.0679, -0.0348, -0.0490,  ..., -0.0161,  0.0714,  0.0065],\n        [ 0.0832, -0.0447, -0.0308,  ..., -0.0087, -0.0252,  0.0545]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	128,
                                                        "out_features":	128,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=128, out_features=4, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0571, -0.0883,  0.0145,  0.0031], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 3.2408e-03,  2.3804e-02, -4.4897e-02, -8.4998e-02,  5.1698e-02,\n          4.1368e-02, -5.8165e-02, -1.9660e-02, -4.9603e-02, -8.4468e-02,\n         -4.4335e-02, -8.0877e-03, -8.5714e-02, -6.4033e-02, -5.3255e-02,\n         -5.0570e-02,  5.7013e-02, -7.2106e-02,  2.0540e-02, -7.4664e-02,\n          8.4395e-02,  6.4749e-02, -6.7992e-02,  6.8514e-02, -6.0261e-03,\n          6.8250e-02,  8.6297e-02,  5.1154e-02, -3.5409e-02,  3.4656e-02,\n         -1.5112e-02, -4.5563e-02,  2.3752e-02,  9.9270e-03, -1.2443e-02,\n         -5.3499e-02, -4.2483e-02, -7.7338e-02, -9.9161e-04, -4.2665e-02,\n         -1.6294e-02,  5.4196e-02,  5.8036e-02, -6.9239e-02,  5.9748e-04,\n         -5.3259e-02, -2.7219e-02,  8.2978e-02,  2.2770e-02, -7.6573e-02,\n         -2.4867e-02, -6.0921e-02,  3.3739e-02,  5.4899e-02, -8.0760e-02,\n          4.3505e-02, -1.8803e-02,  6.2339e-02, -5.3063e-02,  5.8119e-02,\n          8.7140e-02, -7.5637e-02, -6.4245e-02,  2.4496e-02, -3.3550e-02,\n         -7.7845e-03, -7.2740e-02,  4.3855e-02,  8.2278e-02, -7.3779e-02,\n          4.2277e-02,  6.5958e-02, -8.1835e-02, -7.1567e-02, -1.5191e-02,\n          4.2639e-02, -6.2311e-02,  2.1186e-02, -7.8888e-02,  4.5405e-02,\n         -8.2870e-02, -4.9608e-02, -3.1392e-02, -5.6157e-02,  2.2077e-02,\n          1.3036e-02,  5.8486e-02, -7.4323e-02,  5.9690e-02, -5.4382e-02,\n         -5.9736e-02,  4.6679e-02, -5.0947e-02, -1.9368e-02, -7.4995e-02,\n         -7.4000e-02, -5.0642e-02,  6.9039e-02, -2.8873e-03,  6.5645e-02,\n         -2.5093e-02,  7.0934e-02, -5.2879e-02,  4.4425e-02, -7.8650e-02,\n          7.8559e-02, -7.1513e-02,  8.4163e-03, -6.8637e-02,  3.0290e-02,\n         -1.8142e-02, -2.4631e-02,  7.5719e-02,  6.1503e-03,  5.0255e-02,\n         -5.4432e-02, -7.1647e-02, -1.9476e-02, -7.2022e-02,  4.1481e-02,\n         -3.9287e-02,  3.9766e-02, -7.6573e-03,  5.9425e-02, -8.3546e-03,\n          6.7128e-03, -4.0377e-05, -2.5244e-02],\n        [ 4.8705e-02, -2.0127e-02,  4.1086e-02, -2.2232e-02,  2.5845e-02,\n         -7.4967e-02,  5.1814e-02, -3.8343e-02,  4.8504e-02, -7.1572e-02,\n         -4.9877e-02,  7.1158e-02, -4.1964e-04,  1.0697e-02,  1.8394e-02,\n          6.6368e-02,  1.9548e-02, -8.0336e-02, -1.7205e-02, -8.2342e-02,\n          6.1499e-03, -1.8126e-02,  3.0036e-02, -4.3480e-02,  8.7841e-02,\n          6.3247e-02, -6.7282e-03,  4.7496e-02,  7.1962e-02,  5.2564e-03,\n          2.9925e-02,  6.3000e-02, -7.1286e-02,  1.5208e-02, -1.7644e-02,\n         -7.6246e-02, -7.9254e-02, -8.3049e-03,  4.6650e-02,  1.5627e-02,\n          3.4934e-02, -7.9726e-02, -5.6946e-02,  2.7873e-02,  1.2006e-02,\n         -5.9060e-02, -7.9109e-02,  1.6609e-02, -7.8297e-02, -4.5898e-02,\n         -4.2090e-03,  2.8556e-02,  6.4188e-02,  6.3402e-02,  9.9790e-03,\n          8.0540e-02, -3.3686e-02, -5.8937e-02,  7.6243e-02,  5.9593e-02,\n          4.7817e-02, -1.5253e-02,  6.4938e-05,  1.9998e-02, -4.4596e-02,\n          5.5428e-02,  3.4426e-02,  8.3777e-02,  6.4243e-02,  7.3829e-04,\n         -2.0083e-02, -4.1565e-02,  4.0106e-02, -3.8851e-02, -4.7678e-02,\n          3.7281e-02,  6.3854e-02, -7.6815e-02,  5.7395e-02, -2.1198e-02,\n          2.8741e-02, -1.4870e-02, -6.6689e-03,  4.9819e-03,  6.0564e-02,\n         -4.9589e-02, -2.3124e-02, -8.6619e-02, -4.5980e-02, -8.8526e-03,\n         -8.0003e-02,  2.7791e-02,  5.4151e-03,  6.7938e-02,  7.2812e-02,\n          7.5592e-02, -1.4443e-02,  5.6324e-03,  5.1547e-02,  3.1226e-02,\n         -2.8384e-02,  2.7382e-02, -3.7435e-02,  6.7703e-02,  5.1887e-02,\n          3.3785e-02,  3.4885e-02, -6.9570e-02, -7.6559e-02, -2.5998e-02,\n          8.6368e-02,  1.1582e-03,  7.3637e-02,  9.9150e-03, -8.2072e-02,\n          5.3822e-02,  8.7609e-02,  5.6033e-02, -3.9550e-02,  3.8382e-02,\n          7.0285e-02, -3.6072e-03, -7.7258e-02,  8.6726e-02,  7.8737e-03,\n          3.5911e-02, -2.1599e-02,  2.6676e-02],\n        [ 5.0265e-02,  1.1159e-02, -5.2938e-02, -1.6449e-02, -7.4750e-02,\n         -3.0718e-03,  8.0577e-02, -5.5754e-02, -8.2491e-02,  1.0653e-02,\n         -3.1761e-02,  5.0112e-02, -1.5299e-02, -1.4466e-02, -1.8778e-02,\n         -6.2890e-03,  2.2308e-02,  5.7236e-02,  4.9110e-02,  4.0775e-03,\n         -7.6027e-02, -4.0597e-02,  3.6351e-02,  5.4208e-02, -3.7576e-02,\n         -3.4408e-02, -9.9641e-03,  6.4381e-02, -6.4864e-02, -8.2077e-02,\n          3.5753e-02,  1.4351e-03, -2.5756e-02, -3.3714e-02, -4.1437e-02,\n          1.9634e-02, -2.2892e-02, -8.0468e-02,  8.6739e-02,  8.6144e-02,\n          5.4449e-02,  6.2129e-02, -4.5112e-02,  2.9475e-02,  8.5189e-02,\n         -1.5445e-02, -7.2849e-02, -4.1279e-02, -7.5609e-02, -2.8596e-02,\n          6.3624e-03, -7.5419e-02,  7.5639e-02,  2.1571e-02, -5.7124e-02,\n         -8.1812e-02, -5.6683e-02,  5.3822e-02,  2.1310e-03, -3.8069e-02,\n          7.4196e-02, -7.4167e-02, -8.4667e-02,  1.7423e-02, -7.6179e-02,\n         -5.9721e-02,  7.6569e-02, -7.4449e-02,  4.3850e-02, -2.7665e-02,\n          7.8458e-02,  2.2933e-03, -5.9650e-02, -4.5743e-02, -6.1002e-02,\n         -5.8024e-02,  4.0493e-02, -3.2892e-02,  3.5919e-03,  6.4329e-02,\n          4.0217e-02,  1.8257e-02,  7.7695e-03, -8.0919e-02,  4.6196e-02,\n          8.4825e-02,  7.0248e-02, -3.4006e-02, -6.7465e-02, -3.9092e-03,\n          7.3251e-02, -7.3783e-02, -6.9327e-02, -5.5616e-02,  6.0106e-02,\n         -8.0197e-02, -6.5368e-02, -4.4503e-02, -4.0845e-02, -5.9665e-02,\n          5.7831e-02,  7.3076e-02,  7.4295e-02,  3.4374e-02,  4.7137e-02,\n         -3.4264e-02,  1.8440e-02,  1.0585e-02,  3.6208e-02, -7.7653e-02,\n         -7.1879e-02, -5.2796e-02,  5.0850e-02,  9.3131e-03, -2.4005e-02,\n          1.9485e-02,  8.2999e-02,  8.6622e-02,  3.7424e-02,  6.9031e-02,\n          2.2761e-02,  8.4261e-02,  7.6752e-02,  3.2788e-02,  6.8510e-02,\n         -7.2152e-03, -5.1339e-02, -4.5884e-02],\n        [ 5.1540e-02,  6.3921e-02, -5.2607e-02, -4.8130e-02,  7.3410e-02,\n          5.4359e-02,  3.6090e-02,  7.5334e-02,  3.9091e-02, -3.7403e-02,\n          3.3693e-03, -5.4701e-02,  4.0107e-02,  2.5103e-02,  4.6808e-02,\n         -3.2888e-02, -7.3139e-02, -2.3502e-02, -4.7260e-02, -8.3395e-02,\n         -4.7619e-02, -7.2141e-02, -1.0219e-02, -8.6443e-02,  4.1830e-02,\n          6.6663e-02,  1.2774e-02,  8.4565e-02,  8.9814e-03, -6.2549e-02,\n         -6.2425e-02,  3.0915e-02, -3.2607e-02, -4.6149e-02, -2.6652e-02,\n          7.3339e-02,  1.4211e-03, -5.7402e-02,  3.2965e-03,  4.7198e-02,\n          5.0795e-02,  7.7364e-02,  2.4557e-02,  8.2676e-02, -6.9303e-02,\n          3.9402e-02, -6.1660e-02,  8.3105e-03,  5.7538e-02, -5.6369e-02,\n         -6.1587e-02, -8.4841e-02, -4.2705e-02,  3.4714e-03, -2.7841e-02,\n          4.1104e-02,  8.7927e-02,  4.9908e-03,  6.0301e-02, -1.2477e-02,\n         -6.8425e-02,  1.3216e-03, -8.3276e-02,  1.5687e-02,  4.8383e-02,\n         -3.4778e-02,  6.3770e-02, -3.0039e-02,  8.1892e-03,  4.1787e-02,\n         -2.3698e-02,  1.6604e-02,  1.5751e-02,  3.9551e-02,  1.0533e-02,\n          8.4441e-03,  4.4397e-02, -7.6388e-02, -4.1431e-02, -1.6929e-02,\n         -4.2032e-02,  1.3388e-02,  2.4170e-02,  2.2134e-03, -6.1846e-02,\n          7.3577e-02, -6.5274e-02, -6.6412e-02,  9.8245e-03, -6.5823e-02,\n          1.6044e-02, -2.6902e-02, -1.7814e-02,  8.7557e-02,  7.4549e-02,\n         -2.4352e-02,  2.2223e-03, -2.5129e-02,  8.1353e-02, -2.5840e-02,\n         -3.0754e-02, -3.8668e-02,  1.0334e-02, -8.5010e-02, -5.1000e-02,\n         -3.2990e-02,  1.0445e-02,  8.3095e-02,  3.2793e-02,  5.2402e-02,\n         -1.3550e-02, -2.1340e-02, -5.8872e-02, -2.5886e-02,  3.4503e-02,\n         -4.9630e-02,  1.8404e-02,  6.6650e-02,  4.6941e-02,  8.4242e-02,\n          7.6972e-03,  5.3447e-03, -5.5343e-02,  5.1557e-02, -1.8471e-02,\n         -2.9128e-02, -6.7642e-03,  8.2947e-02]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	128,
                                                        "out_features":	4,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "custom_network":	null,
                    "input_dim":	8,
                    "output_dim":	4,
                    "training":	true
                }
            },
            "_pi_lr":	0.0003000000142492354,
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003000000142492354\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003000000142492354,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003000000142492354,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2413,  0.1591,  0.2084,  ..., -0.1059, -0.3359,  0.1043],\n        [-0.1823,  0.1796, -0.3137,  ...,  0.2922, -0.2141, -0.3420],\n        [-0.2996, -0.2075, -0.0080,  ...,  0.1062, -0.3055,  0.2452],\n        ...,\n        [ 0.0285,  0.3223, -0.2581,  ..., -0.1472,  0.2594,  0.0720],\n        [-0.0867, -0.2193, -0.1792,  ..., -0.2298, -0.1688,  0.2420],\n        [ 0.2575,  0.3113, -0.0134,  ..., -0.3346,  0.2927,  0.2124]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0202,  0.3366, -0.0133, -0.0544,  0.0859,  0.1155,  0.0354,  0.2983,\n         0.1444,  0.1930, -0.3297,  0.0438,  0.2007,  0.0621,  0.1840, -0.1473,\n         0.0123, -0.0091, -0.1914, -0.2155,  0.1469, -0.3433, -0.1309, -0.0076,\n        -0.2790, -0.1367,  0.2647, -0.1974, -0.0803, -0.0572, -0.2620, -0.0549,\n        -0.0468,  0.2793,  0.1670, -0.3063,  0.2274, -0.2572, -0.1864,  0.2038,\n        -0.0910, -0.1179,  0.0107, -0.3371,  0.3311,  0.1388, -0.0518,  0.1777,\n        -0.1350, -0.2220,  0.2843,  0.1792,  0.3208, -0.2198, -0.2283, -0.0254,\n         0.0894, -0.0265,  0.0398, -0.0149, -0.2139, -0.2726, -0.1774, -0.2497,\n        -0.3162, -0.0087, -0.3168, -0.1422,  0.3151,  0.1011, -0.2451, -0.2771,\n         0.0177,  0.2165, -0.2344, -0.1818,  0.2646,  0.2697,  0.1603, -0.0923,\n        -0.0748,  0.2465, -0.0981, -0.0760,  0.1595,  0.1468,  0.3386, -0.3230,\n        -0.1821, -0.2381,  0.3073, -0.2822,  0.0039,  0.2635, -0.1951,  0.2515,\n         0.0315, -0.3137,  0.3186, -0.1614, -0.0782,  0.1205, -0.0468,  0.2799,\n        -0.2670, -0.3166,  0.0215,  0.3222,  0.1971,  0.2061,  0.2195, -0.0547,\n         0.1173,  0.0903,  0.0780, -0.3184,  0.3425,  0.0472,  0.1205, -0.2312,\n        -0.0814,  0.0281,  0.2535, -0.3122, -0.0525, -0.0267,  0.1377, -0.1100],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0738,  0.0194,  0.0528,  ...,  0.0143, -0.0328, -0.0610],\n        [-0.0182, -0.0763, -0.0569,  ...,  0.0861,  0.0622,  0.0855],\n        [-0.0476, -0.0719, -0.0271,  ...,  0.0085,  0.0746,  0.0477],\n        ...,\n        [ 0.0863, -0.0245, -0.0683,  ..., -0.0055, -0.0505,  0.0606],\n        [ 0.0679, -0.0348, -0.0490,  ..., -0.0161,  0.0714,  0.0065],\n        [ 0.0832, -0.0447, -0.0308,  ..., -0.0087, -0.0252,  0.0545]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0685, -0.0594, -0.0819,  0.0040,  0.0379,  0.0253,  0.0676,  0.0291,\n        -0.0067, -0.0782,  0.0757, -0.0117,  0.0378, -0.0843, -0.0370,  0.0799,\n         0.0484,  0.0814, -0.0242, -0.0361,  0.0454,  0.0052,  0.0166,  0.0018,\n         0.0105, -0.0003, -0.0097,  0.0340, -0.0384, -0.0298,  0.0113, -0.0551,\n        -0.0224, -0.0473,  0.0189, -0.0629, -0.0578, -0.0306, -0.0315, -0.0583,\n         0.0169, -0.0205,  0.0491, -0.0777, -0.0382,  0.0029, -0.0167,  0.0590,\n         0.0527,  0.0565,  0.0803, -0.0492, -0.0138, -0.0015, -0.0011,  0.0180,\n        -0.0143, -0.0475, -0.0358,  0.0181,  0.0310,  0.0862, -0.0505, -0.0348,\n        -0.0581, -0.0135,  0.0490, -0.0589,  0.0281, -0.0800,  0.0005, -0.0828,\n        -0.0316, -0.0316,  0.0162, -0.0746,  0.0689,  0.0415,  0.0196, -0.0424,\n        -0.0550,  0.0653,  0.0443,  0.0347, -0.0555, -0.0509, -0.0611,  0.0348,\n         0.0872, -0.0823,  0.0882, -0.0729, -0.0868,  0.0011,  0.0321,  0.0209,\n         0.0551,  0.0592, -0.0158,  0.0221, -0.0702,  0.0471,  0.0021, -0.0785,\n         0.0282,  0.0651,  0.0306, -0.0245, -0.0619,  0.0840,  0.0076, -0.0779,\n        -0.0082,  0.0375, -0.0459,  0.0502, -0.0067,  0.0371,  0.0326,  0.0111,\n         0.0880, -0.0129, -0.0636, -0.0408, -0.0102, -0.0133, -0.0787,  0.0277],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 3.2408e-03,  2.3804e-02, -4.4897e-02, -8.4998e-02,  5.1698e-02,\n          4.1368e-02, -5.8165e-02, -1.9660e-02, -4.9603e-02, -8.4468e-02,\n         -4.4335e-02, -8.0877e-03, -8.5714e-02, -6.4033e-02, -5.3255e-02,\n         -5.0570e-02,  5.7013e-02, -7.2106e-02,  2.0540e-02, -7.4664e-02,\n          8.4395e-02,  6.4749e-02, -6.7992e-02,  6.8514e-02, -6.0261e-03,\n          6.8250e-02,  8.6297e-02,  5.1154e-02, -3.5409e-02,  3.4656e-02,\n         -1.5112e-02, -4.5563e-02,  2.3752e-02,  9.9270e-03, -1.2443e-02,\n         -5.3499e-02, -4.2483e-02, -7.7338e-02, -9.9161e-04, -4.2665e-02,\n         -1.6294e-02,  5.4196e-02,  5.8036e-02, -6.9239e-02,  5.9748e-04,\n         -5.3259e-02, -2.7219e-02,  8.2978e-02,  2.2770e-02, -7.6573e-02,\n         -2.4867e-02, -6.0921e-02,  3.3739e-02,  5.4899e-02, -8.0760e-02,\n          4.3505e-02, -1.8803e-02,  6.2339e-02, -5.3063e-02,  5.8119e-02,\n          8.7140e-02, -7.5637e-02, -6.4245e-02,  2.4496e-02, -3.3550e-02,\n         -7.7845e-03, -7.2740e-02,  4.3855e-02,  8.2278e-02, -7.3779e-02,\n          4.2277e-02,  6.5958e-02, -8.1835e-02, -7.1567e-02, -1.5191e-02,\n          4.2639e-02, -6.2311e-02,  2.1186e-02, -7.8888e-02,  4.5405e-02,\n         -8.2870e-02, -4.9608e-02, -3.1392e-02, -5.6157e-02,  2.2077e-02,\n          1.3036e-02,  5.8486e-02, -7.4323e-02,  5.9690e-02, -5.4382e-02,\n         -5.9736e-02,  4.6679e-02, -5.0947e-02, -1.9368e-02, -7.4995e-02,\n         -7.4000e-02, -5.0642e-02,  6.9039e-02, -2.8873e-03,  6.5645e-02,\n         -2.5093e-02,  7.0934e-02, -5.2879e-02,  4.4425e-02, -7.8650e-02,\n          7.8559e-02, -7.1513e-02,  8.4163e-03, -6.8637e-02,  3.0290e-02,\n         -1.8142e-02, -2.4631e-02,  7.5719e-02,  6.1503e-03,  5.0255e-02,\n         -5.4432e-02, -7.1647e-02, -1.9476e-02, -7.2022e-02,  4.1481e-02,\n         -3.9287e-02,  3.9766e-02, -7.6573e-03,  5.9425e-02, -8.3546e-03,\n          6.7128e-03, -4.0377e-05, -2.5244e-02],\n        [ 4.8705e-02, -2.0127e-02,  4.1086e-02, -2.2232e-02,  2.5845e-02,\n         -7.4967e-02,  5.1814e-02, -3.8343e-02,  4.8504e-02, -7.1572e-02,\n         -4.9877e-02,  7.1158e-02, -4.1964e-04,  1.0697e-02,  1.8394e-02,\n          6.6368e-02,  1.9548e-02, -8.0336e-02, -1.7205e-02, -8.2342e-02,\n          6.1499e-03, -1.8126e-02,  3.0036e-02, -4.3480e-02,  8.7841e-02,\n          6.3247e-02, -6.7282e-03,  4.7496e-02,  7.1962e-02,  5.2564e-03,\n          2.9925e-02,  6.3000e-02, -7.1286e-02,  1.5208e-02, -1.7644e-02,\n         -7.6246e-02, -7.9254e-02, -8.3049e-03,  4.6650e-02,  1.5627e-02,\n          3.4934e-02, -7.9726e-02, -5.6946e-02,  2.7873e-02,  1.2006e-02,\n         -5.9060e-02, -7.9109e-02,  1.6609e-02, -7.8297e-02, -4.5898e-02,\n         -4.2090e-03,  2.8556e-02,  6.4188e-02,  6.3402e-02,  9.9790e-03,\n          8.0540e-02, -3.3686e-02, -5.8937e-02,  7.6243e-02,  5.9593e-02,\n          4.7817e-02, -1.5253e-02,  6.4938e-05,  1.9998e-02, -4.4596e-02,\n          5.5428e-02,  3.4426e-02,  8.3777e-02,  6.4243e-02,  7.3829e-04,\n         -2.0083e-02, -4.1565e-02,  4.0106e-02, -3.8851e-02, -4.7678e-02,\n          3.7281e-02,  6.3854e-02, -7.6815e-02,  5.7395e-02, -2.1198e-02,\n          2.8741e-02, -1.4870e-02, -6.6689e-03,  4.9819e-03,  6.0564e-02,\n         -4.9589e-02, -2.3124e-02, -8.6619e-02, -4.5980e-02, -8.8526e-03,\n         -8.0003e-02,  2.7791e-02,  5.4151e-03,  6.7938e-02,  7.2812e-02,\n          7.5592e-02, -1.4443e-02,  5.6324e-03,  5.1547e-02,  3.1226e-02,\n         -2.8384e-02,  2.7382e-02, -3.7435e-02,  6.7703e-02,  5.1887e-02,\n          3.3785e-02,  3.4885e-02, -6.9570e-02, -7.6559e-02, -2.5998e-02,\n          8.6368e-02,  1.1582e-03,  7.3637e-02,  9.9150e-03, -8.2072e-02,\n          5.3822e-02,  8.7609e-02,  5.6033e-02, -3.9550e-02,  3.8382e-02,\n          7.0285e-02, -3.6072e-03, -7.7258e-02,  8.6726e-02,  7.8737e-03,\n          3.5911e-02, -2.1599e-02,  2.6676e-02],\n        [ 5.0265e-02,  1.1159e-02, -5.2938e-02, -1.6449e-02, -7.4750e-02,\n         -3.0718e-03,  8.0577e-02, -5.5754e-02, -8.2491e-02,  1.0653e-02,\n         -3.1761e-02,  5.0112e-02, -1.5299e-02, -1.4466e-02, -1.8778e-02,\n         -6.2890e-03,  2.2308e-02,  5.7236e-02,  4.9110e-02,  4.0775e-03,\n         -7.6027e-02, -4.0597e-02,  3.6351e-02,  5.4208e-02, -3.7576e-02,\n         -3.4408e-02, -9.9641e-03,  6.4381e-02, -6.4864e-02, -8.2077e-02,\n          3.5753e-02,  1.4351e-03, -2.5756e-02, -3.3714e-02, -4.1437e-02,\n          1.9634e-02, -2.2892e-02, -8.0468e-02,  8.6739e-02,  8.6144e-02,\n          5.4449e-02,  6.2129e-02, -4.5112e-02,  2.9475e-02,  8.5189e-02,\n         -1.5445e-02, -7.2849e-02, -4.1279e-02, -7.5609e-02, -2.8596e-02,\n          6.3624e-03, -7.5419e-02,  7.5639e-02,  2.1571e-02, -5.7124e-02,\n         -8.1812e-02, -5.6683e-02,  5.3822e-02,  2.1310e-03, -3.8069e-02,\n          7.4196e-02, -7.4167e-02, -8.4667e-02,  1.7423e-02, -7.6179e-02,\n         -5.9721e-02,  7.6569e-02, -7.4449e-02,  4.3850e-02, -2.7665e-02,\n          7.8458e-02,  2.2933e-03, -5.9650e-02, -4.5743e-02, -6.1002e-02,\n         -5.8024e-02,  4.0493e-02, -3.2892e-02,  3.5919e-03,  6.4329e-02,\n          4.0217e-02,  1.8257e-02,  7.7695e-03, -8.0919e-02,  4.6196e-02,\n          8.4825e-02,  7.0248e-02, -3.4006e-02, -6.7465e-02, -3.9092e-03,\n          7.3251e-02, -7.3783e-02, -6.9327e-02, -5.5616e-02,  6.0106e-02,\n         -8.0197e-02, -6.5368e-02, -4.4503e-02, -4.0845e-02, -5.9665e-02,\n          5.7831e-02,  7.3076e-02,  7.4295e-02,  3.4374e-02,  4.7137e-02,\n         -3.4264e-02,  1.8440e-02,  1.0585e-02,  3.6208e-02, -7.7653e-02,\n         -7.1879e-02, -5.2796e-02,  5.0850e-02,  9.3131e-03, -2.4005e-02,\n          1.9485e-02,  8.2999e-02,  8.6622e-02,  3.7424e-02,  6.9031e-02,\n          2.2761e-02,  8.4261e-02,  7.6752e-02,  3.2788e-02,  6.8510e-02,\n         -7.2152e-03, -5.1339e-02, -4.5884e-02],\n        [ 5.1540e-02,  6.3921e-02, -5.2607e-02, -4.8130e-02,  7.3410e-02,\n          5.4359e-02,  3.6090e-02,  7.5334e-02,  3.9091e-02, -3.7403e-02,\n          3.3693e-03, -5.4701e-02,  4.0107e-02,  2.5103e-02,  4.6808e-02,\n         -3.2888e-02, -7.3139e-02, -2.3502e-02, -4.7260e-02, -8.3395e-02,\n         -4.7619e-02, -7.2141e-02, -1.0219e-02, -8.6443e-02,  4.1830e-02,\n          6.6663e-02,  1.2774e-02,  8.4565e-02,  8.9814e-03, -6.2549e-02,\n         -6.2425e-02,  3.0915e-02, -3.2607e-02, -4.6149e-02, -2.6652e-02,\n          7.3339e-02,  1.4211e-03, -5.7402e-02,  3.2965e-03,  4.7198e-02,\n          5.0795e-02,  7.7364e-02,  2.4557e-02,  8.2676e-02, -6.9303e-02,\n          3.9402e-02, -6.1660e-02,  8.3105e-03,  5.7538e-02, -5.6369e-02,\n         -6.1587e-02, -8.4841e-02, -4.2705e-02,  3.4714e-03, -2.7841e-02,\n          4.1104e-02,  8.7927e-02,  4.9908e-03,  6.0301e-02, -1.2477e-02,\n         -6.8425e-02,  1.3216e-03, -8.3276e-02,  1.5687e-02,  4.8383e-02,\n         -3.4778e-02,  6.3770e-02, -3.0039e-02,  8.1892e-03,  4.1787e-02,\n         -2.3698e-02,  1.6604e-02,  1.5751e-02,  3.9551e-02,  1.0533e-02,\n          8.4441e-03,  4.4397e-02, -7.6388e-02, -4.1431e-02, -1.6929e-02,\n         -4.2032e-02,  1.3388e-02,  2.4170e-02,  2.2134e-03, -6.1846e-02,\n          7.3577e-02, -6.5274e-02, -6.6412e-02,  9.8245e-03, -6.5823e-02,\n          1.6044e-02, -2.6902e-02, -1.7814e-02,  8.7557e-02,  7.4549e-02,\n         -2.4352e-02,  2.2223e-03, -2.5129e-02,  8.1353e-02, -2.5840e-02,\n         -3.0754e-02, -3.8668e-02,  1.0334e-02, -8.5010e-02, -5.1000e-02,\n         -3.2990e-02,  1.0445e-02,  8.3095e-02,  3.2793e-02,  5.2402e-02,\n         -1.3550e-02, -2.1340e-02, -5.8872e-02, -2.5886e-02,  3.4503e-02,\n         -4.9630e-02,  1.8404e-02,  6.6650e-02,  4.6941e-02,  8.4242e-02,\n          7.6972e-03,  5.3447e-03, -5.5343e-02,  5.1557e-02, -1.8471e-02,\n         -2.9128e-02, -6.7642e-03,  8.2947e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0571, -0.0883,  0.0145,  0.0031], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<REINFORCE.replay_buffer.ReplayBuffer object at 0x108992ac0>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	1000000,
                    "gamma":	0.9800000190734863,
                    "lam":	0.9700000286102295,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n ...\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]]",
                    "max_size":	1000000,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "with_vf_baseline":	false
                }
            },
            "_seed":	1,
            "_train_vf_iters":	80,
            "_traj_per_epoch":	8,
            "_vf_lr":	0.0010000000474974513,
            "_with_vf_baseline":	false,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x133e8c850>":	{
                    "epoch_dict":	{},
                    "exp_name":	"relayrl-reinforce-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"././logs/relayrl-reinforce-info/relayrl-reinforce-info_s279670001",
                    "output_file":	{
                        "<_io.TextIOWrapper name='././logs/relayrl-reinforce-info/relayrl-reinforce-info_s279670001/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "save_model_path":	"/Users/tybg/Documents/GitHub/RelayRL-prototype/examples/REINFORCE/box2d/lunar_lander/zmq/server_model.pt"
        }
    }
}