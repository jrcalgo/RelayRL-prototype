{
    "__class__":	"REINFORCE",
    "act_dim":	4,
    "buf_size":	1000000,
    "config_loader":	"<builtins.ConfigLoader object at 0x102632e90>",
    "config_path":	"relayrl_config.json",
    "env_dir":	".",
    "exp_name":	"relayrl-reinforce-info",
    "hyperparams":	{
        "discrete":	true,
        "gamma":	0.9800000190734863,
        "lam":	0.9700000286102295,
        "pi_lr":	0.0003000000142492354,
        "seed":	1,
        "train_vf_iters":	80,
        "traj_per_epoch":	8,
        "vf_lr":	0.0010000000474974513,
        "with_vf_baseline":	false
    },
    "log_data_dir":	"././logs/",
    "logger_kwargs":	{
        "exp_name":	"relayrl-reinforce-info",
        "output_dir":	"././logs/relayrl-reinforce-info/relayrl-reinforce-info_s256470001"
    },
    "obs_dim":	8,
    "seed":	256470001,
    "self":	{
        "<REINFORCE.REINFORCE.REINFORCE object at 0x102657cd0>":	{
            "_discrete":	true,
            "_gamma":	0.9800000190734863,
            "_lam":	0.9700000286102295,
            "_model":	{
                "PolicyWithoutBaseline(\n  (policy): DiscretePolicyNetwork(\n    (pi_network): Sequential(\n      (0): Linear(in_features=8, out_features=128, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=128, out_features=4, bias=True)\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "policy":	{
                            "DiscretePolicyNetwork(\n  (pi_network): Sequential(\n    (0): Linear(in_features=8, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=128, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=128, out_features=4, bias=True)\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "pi_network":	{
                                        "Sequential(\n  (0): Linear(in_features=8, out_features=128, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=128, out_features=128, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=8, out_features=128, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0243,  0.0803,  0.2503,  0.0851, -0.3004, -0.3275, -0.0481,  0.2841,\n        -0.0177,  0.3231,  0.2075, -0.1872, -0.1776,  0.0656, -0.1392, -0.0482,\n         0.1686,  0.0535,  0.3090, -0.0431,  0.0915, -0.2558, -0.1086, -0.1365,\n        -0.1367, -0.0295,  0.1250,  0.0432,  0.1687, -0.2725,  0.1635,  0.3199,\n         0.2558, -0.1347, -0.1827,  0.2895,  0.0876, -0.1423, -0.3496,  0.2381,\n        -0.2893, -0.1021, -0.2264, -0.0436, -0.2518,  0.0079,  0.2062,  0.1163,\n         0.2290, -0.1067, -0.0620, -0.1534,  0.0939,  0.1008,  0.1205, -0.0796,\n         0.3432,  0.1593,  0.1492, -0.1777, -0.2868, -0.0531,  0.3070,  0.1192,\n        -0.1672,  0.0717, -0.0876,  0.0413,  0.2249,  0.1353,  0.3130, -0.3282,\n        -0.1706,  0.2766, -0.0944, -0.3228,  0.1386, -0.1641, -0.1741, -0.1194,\n        -0.0930,  0.2033,  0.0097, -0.3477,  0.0270, -0.0562, -0.0197,  0.0755,\n        -0.0594,  0.1486, -0.2716, -0.1870, -0.3089, -0.1436,  0.0502,  0.2866,\n         0.3129,  0.0542,  0.1463, -0.2764, -0.0906, -0.2637,  0.1772,  0.2578,\n        -0.2401,  0.2447, -0.3398,  0.0775, -0.2478,  0.3470, -0.2868, -0.0992,\n         0.2504, -0.2531,  0.0025, -0.0226, -0.3246, -0.1553, -0.3505, -0.0127,\n         0.3314,  0.2870, -0.3066, -0.2647,  0.1555, -0.0097, -0.1899,  0.0263],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0013, -0.1285, -0.1103,  ...,  0.1271, -0.1709,  0.0902],\n        [-0.0240,  0.2325, -0.2626,  ..., -0.0472, -0.3131,  0.0190],\n        [ 0.2811, -0.2875, -0.1179,  ..., -0.3526,  0.1191,  0.1908],\n        ...,\n        [ 0.1634,  0.2225, -0.2164,  ...,  0.1222, -0.0606,  0.2904],\n        [ 0.3353, -0.2209,  0.2938,  ..., -0.0916, -0.1972,  0.2275],\n        [-0.0475,  0.0032,  0.2279,  ..., -0.0646,  0.0437, -0.0329]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	128,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=128, out_features=128, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0507,  0.0322, -0.0754,  0.0183, -0.0360, -0.0019, -0.0443, -0.0270,\n        -0.0108, -0.0817,  0.0116, -0.0640,  0.0154,  0.0031, -0.0456, -0.0468,\n        -0.0732,  0.0792,  0.0711,  0.0715,  0.0767, -0.0301, -0.0455,  0.0726,\n         0.0587, -0.0144, -0.0540,  0.0270,  0.0688,  0.0825, -0.0681,  0.0707,\n        -0.0615, -0.0770,  0.0364,  0.0750,  0.0164, -0.0349,  0.0722,  0.0072,\n         0.0362,  0.0614, -0.0798,  0.0397, -0.0743, -0.0360,  0.0756, -0.0139,\n         0.0639,  0.0119, -0.0184, -0.0077, -0.0703, -0.0217, -0.0612, -0.0412,\n         0.0622, -0.0621,  0.0067,  0.0564,  0.0406, -0.0791, -0.0392, -0.0539,\n         0.0142, -0.0617,  0.0490, -0.0664, -0.0702,  0.0686, -0.0048, -0.0119,\n        -0.0689,  0.0878, -0.0243, -0.0160,  0.0198, -0.0299, -0.0404, -0.0480,\n        -0.0296, -0.0643, -0.0478, -0.0175, -0.0017,  0.0255, -0.0477,  0.0638,\n         0.0662, -0.0604, -0.0064,  0.0355, -0.0470, -0.0115,  0.0426, -0.0783,\n         0.0433,  0.0783, -0.0123, -0.0871, -0.0310,  0.0016,  0.0310,  0.0391,\n        -0.0422,  0.0683, -0.0446,  0.0361, -0.0102,  0.0327,  0.0353,  0.0537,\n         0.0520, -0.0530,  0.0843,  0.0769, -0.0237,  0.0606,  0.0343,  0.0576,\n        -0.0884,  0.0265, -0.0315, -0.0723, -0.0683,  0.0669, -0.0374, -0.0217],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0463, -0.0591,  0.0025,  ..., -0.0454,  0.0035,  0.0598],\n        [ 0.0677, -0.0382,  0.0045,  ..., -0.0443, -0.0059, -0.0085],\n        [ 0.0213,  0.0261, -0.0876,  ..., -0.0860,  0.0532,  0.0821],\n        ...,\n        [-0.0032, -0.0758,  0.0682,  ..., -0.0435,  0.0085, -0.0225],\n        [-0.0160,  0.0386, -0.0002,  ..., -0.0131, -0.0426, -0.0119],\n        [-0.0793, -0.0447, -0.0508,  ..., -0.0077, -0.0670,  0.0128]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	128,
                                                        "out_features":	128,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=128, out_features=4, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0329, -0.0148, -0.0064, -0.0586], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 6.2084e-02, -1.5669e-02,  3.1787e-02, -6.7608e-02,  2.7619e-03,\n          4.1661e-02, -3.4264e-02,  5.5230e-02,  7.9658e-03,  2.0920e-02,\n         -4.2964e-02,  2.0548e-02, -4.0697e-02,  5.8791e-02, -3.6201e-02,\n         -2.8617e-02, -1.6100e-02, -8.5393e-02,  7.4248e-02,  4.7841e-02,\n          4.6021e-02, -6.9631e-02, -5.6546e-02,  5.4073e-02, -4.9203e-02,\n         -4.4036e-02,  1.0897e-02, -4.9033e-02, -4.5477e-02,  4.1485e-02,\n         -5.4938e-02, -2.2462e-02, -1.1506e-02, -3.5880e-02, -7.4979e-02,\n          2.1340e-03, -5.8069e-02, -1.7659e-02,  2.7226e-02,  6.9133e-02,\n          8.2791e-02,  3.7268e-02,  6.8351e-02,  2.3774e-02, -6.8612e-02,\n         -6.2549e-02,  6.3282e-02, -6.2318e-02, -6.5393e-02,  6.6616e-02,\n          2.7113e-02,  2.1753e-02,  7.0283e-02,  7.0385e-02, -6.3161e-02,\n          6.4216e-02, -8.4908e-02,  7.2432e-02, -2.2487e-02,  6.7498e-02,\n         -7.6922e-02,  5.9189e-02, -1.0614e-02, -8.1008e-02,  3.3976e-02,\n          7.7543e-02,  7.3899e-02, -3.3913e-03,  6.1710e-02,  3.4852e-03,\n          4.3505e-02,  2.3675e-02, -1.2804e-03,  8.6422e-02, -4.6302e-02,\n         -4.9508e-02, -8.2463e-02,  7.8091e-02, -5.4860e-02,  2.5327e-02,\n          1.3844e-02,  1.2052e-02, -1.4737e-02, -1.5640e-02,  3.0123e-02,\n          5.2934e-02, -4.6308e-02,  5.2955e-02, -3.5525e-02, -2.6949e-02,\n          3.4942e-02,  6.4518e-02, -1.7398e-02, -8.0376e-02,  4.1644e-02,\n         -6.1177e-02, -3.4092e-02,  1.4145e-03, -1.9815e-02, -1.3084e-02,\n          4.2238e-02,  6.5500e-02,  2.6890e-02, -1.5362e-02, -8.7000e-02,\n          6.7662e-02, -5.8892e-02, -4.7488e-02,  5.7227e-02,  4.5149e-03,\n          3.1263e-02,  1.0062e-02, -1.4017e-02, -7.9147e-02,  3.5260e-03,\n         -1.3418e-02,  2.9276e-02,  6.4896e-02,  6.2517e-02,  5.6328e-03,\n          7.8890e-03,  6.3218e-02,  2.6644e-02,  4.0565e-02,  4.4391e-02,\n          5.1614e-02,  3.3840e-02, -4.5455e-02],\n        [ 1.3704e-02, -2.5036e-02,  5.0004e-02,  4.7009e-02,  7.0663e-02,\n          7.4317e-03, -5.5007e-02, -3.5941e-05, -6.9658e-02,  7.7079e-02,\n         -5.3213e-03,  2.2507e-02, -7.3295e-02,  3.7369e-03,  8.3216e-02,\n          3.2990e-02,  3.2867e-02, -4.1537e-02, -6.9718e-02, -6.5322e-02,\n          5.6118e-02,  7.1257e-02,  4.3885e-02, -2.3315e-02, -4.7161e-02,\n         -7.0837e-02,  8.0373e-02,  6.4823e-02, -4.6669e-02,  8.2509e-02,\n          5.6478e-02,  7.5605e-03,  1.7106e-02, -7.0580e-02,  7.2733e-02,\n         -4.0440e-02, -1.8923e-02, -4.1306e-02, -4.5284e-02, -7.2010e-02,\n         -3.2913e-02, -8.3351e-02, -3.0219e-02, -9.3178e-03, -8.3292e-02,\n          6.6216e-02,  5.7931e-02, -8.8386e-02, -7.2486e-02, -6.2913e-02,\n          4.2495e-03, -2.7838e-02, -1.5118e-02,  2.8442e-02, -2.0445e-02,\n          2.8219e-02, -2.9479e-02,  4.7274e-02,  3.4666e-02, -4.7672e-02,\n         -5.1729e-02,  4.9576e-02,  4.8422e-03,  3.1312e-02,  3.8180e-02,\n          8.3414e-02, -3.1844e-03,  1.7762e-02,  7.7513e-02,  1.4868e-02,\n         -3.2148e-02,  6.5282e-02,  4.0918e-02,  6.8965e-02, -8.9167e-03,\n          1.6965e-02, -6.0856e-02, -7.9060e-02, -4.8410e-02, -1.2906e-02,\n          5.6179e-02, -8.7268e-02,  2.4439e-02, -5.7828e-02,  1.1602e-02,\n          3.2511e-02, -7.1687e-02,  3.6042e-02,  7.4509e-02, -1.1097e-03,\n          2.6040e-02, -5.4684e-02, -7.9055e-02, -5.0928e-02,  8.2165e-02,\n          7.4376e-02,  1.8219e-02,  6.0814e-02, -4.7645e-02,  1.7844e-02,\n         -3.8690e-02, -4.0844e-02,  2.9288e-02, -5.6876e-02,  1.5330e-02,\n         -6.4789e-03,  4.0277e-02,  5.8593e-02, -4.6357e-02, -3.3659e-02,\n          6.1919e-02, -8.5032e-02,  2.1174e-02,  6.8582e-02,  6.8790e-02,\n          6.3338e-03, -2.6793e-02, -8.2767e-02, -1.4321e-02, -2.9088e-02,\n          4.7379e-02,  1.0355e-02,  5.8249e-02,  5.0755e-02, -8.3469e-02,\n          6.2507e-03,  8.7879e-02, -1.5385e-02],\n        [-5.1340e-02, -5.5102e-02,  8.5515e-02,  2.2003e-03, -6.5157e-02,\n         -7.8225e-02, -6.3774e-02,  6.5103e-02, -2.2279e-02, -7.0125e-02,\n         -9.1579e-03,  1.0042e-02, -8.7524e-02,  6.4801e-02, -1.8281e-02,\n         -5.7571e-03,  7.5102e-02,  2.1422e-02, -6.3333e-03,  2.8750e-02,\n          8.1474e-02, -4.1395e-02, -4.7760e-02, -8.1161e-03, -7.5995e-02,\n          7.9259e-02, -3.3109e-02, -7.7702e-02, -1.6830e-02, -4.1954e-03,\n         -8.7677e-02,  7.6787e-02,  4.1088e-02,  3.3570e-02, -1.1606e-02,\n         -4.8050e-03,  7.9279e-02, -6.9391e-02, -4.1300e-03,  4.8070e-02,\n         -6.5278e-02,  8.1190e-03,  3.3248e-03,  7.2857e-02,  5.4420e-02,\n         -5.4175e-03,  7.3901e-02,  2.1976e-02, -6.5352e-02, -2.8824e-02,\n          2.8904e-02, -3.8418e-03, -1.6180e-02,  7.0378e-02, -1.5643e-02,\n          6.0087e-02,  4.4638e-02, -1.8957e-02,  8.7720e-02,  3.1900e-02,\n          4.3299e-02,  6.0298e-02, -2.0954e-02,  8.0065e-02, -1.1930e-02,\n          1.0902e-03, -3.1372e-02,  5.6046e-02, -4.9750e-02,  6.3258e-02,\n          1.7796e-02, -8.5507e-02,  9.8635e-03, -7.8323e-02, -6.7255e-02,\n         -6.2438e-02,  7.3350e-02, -7.9379e-02, -5.5137e-02, -3.9946e-02,\n         -8.8042e-03,  8.1675e-02, -4.8971e-02, -9.7184e-03,  5.6024e-02,\n         -2.6975e-02, -8.7355e-02,  5.7962e-02,  1.2555e-03, -6.7890e-02,\n         -5.4423e-02,  5.9973e-02,  7.1572e-02,  8.7419e-02, -5.9177e-02,\n          2.0758e-02, -3.4664e-02, -1.4289e-02, -2.5261e-02, -8.2891e-02,\n          3.8909e-02, -5.9239e-03, -1.1662e-03, -1.8566e-02, -6.0791e-02,\n          2.4312e-02, -3.4600e-02, -2.5742e-02,  1.3122e-02,  1.5556e-02,\n         -6.5995e-02, -2.5296e-02,  8.1424e-02,  2.5497e-02,  2.9226e-04,\n          1.6112e-02,  5.7190e-02, -4.9218e-02, -2.3537e-02,  8.1652e-02,\n          8.2853e-02,  8.6568e-02,  2.4966e-02,  4.4063e-02, -4.1761e-02,\n         -7.8369e-02, -1.1885e-03,  1.0945e-02],\n        [ 3.6989e-02,  2.1555e-02,  3.8234e-02,  1.0793e-03,  1.3237e-03,\n         -4.7130e-02,  1.3225e-02, -7.4952e-02, -3.1460e-02, -4.0627e-02,\n          4.9254e-02,  3.5126e-02,  2.6323e-02, -1.3786e-02, -1.8741e-02,\n          1.8499e-02,  1.6960e-02,  1.7678e-02,  7.9835e-02,  5.3578e-02,\n         -2.5982e-02,  4.5499e-02, -3.5720e-02,  7.8884e-02, -5.9895e-02,\n          5.1728e-02, -7.9469e-02, -5.4728e-02,  1.1881e-02,  4.4235e-02,\n         -7.6291e-02, -5.6656e-03,  4.1270e-02,  2.6759e-02, -2.8843e-02,\n          2.1647e-02, -2.4473e-02,  5.4683e-02, -4.5143e-02, -7.3449e-02,\n          5.0860e-02,  7.0527e-02, -8.0925e-02,  4.9616e-02,  4.9490e-02,\n         -3.2684e-02, -3.0557e-02,  1.9501e-02,  5.0490e-02,  5.3181e-02,\n         -3.6451e-02,  3.9827e-04,  4.4522e-02, -2.7348e-02, -2.1583e-02,\n          2.1376e-02, -3.2668e-02, -2.5077e-02,  4.6419e-03,  3.7958e-02,\n         -2.6537e-03, -6.5875e-02,  6.6792e-02,  4.1990e-02, -8.2732e-02,\n         -2.1557e-02,  3.5191e-02, -8.8191e-02, -4.5044e-05, -4.3954e-03,\n         -4.6458e-02,  6.8401e-02,  6.1165e-02, -4.5341e-03, -3.6454e-02,\n         -1.9719e-02, -1.3790e-02, -7.2706e-02,  2.3793e-03, -1.7684e-02,\n         -5.0319e-02, -3.9083e-03, -1.9063e-02,  5.0961e-02, -5.8953e-02,\n          1.6805e-02,  4.6212e-02, -5.8697e-02, -2.0214e-02, -2.3974e-02,\n         -1.7035e-02,  5.6136e-02,  7.8574e-02,  8.8095e-02, -1.5326e-02,\n          5.5688e-02, -8.1484e-02,  5.7274e-03,  3.4034e-02,  4.2689e-02,\n         -4.4497e-02,  4.3473e-02, -4.0741e-03, -6.0528e-02,  2.2266e-02,\n          1.8616e-03, -2.0736e-02, -6.3941e-02,  7.4692e-02, -2.4758e-02,\n          4.8486e-02,  1.1482e-02, -2.4229e-02,  4.5149e-02, -3.5286e-02,\n         -3.6196e-02, -3.8491e-02, -7.1034e-02, -1.9946e-02,  5.8083e-02,\n          6.7823e-02,  7.8730e-02,  8.4397e-02, -2.0910e-03,  7.9169e-02,\n         -5.3207e-02,  8.6487e-02, -3.1413e-02]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	128,
                                                        "out_features":	4,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "custom_network":	null,
                    "input_dim":	8,
                    "output_dim":	4,
                    "training":	true
                }
            },
            "_pi_lr":	0.0003000000142492354,
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003000000142492354\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003000000142492354,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003000000142492354,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0013, -0.1285, -0.1103,  ...,  0.1271, -0.1709,  0.0902],\n        [-0.0240,  0.2325, -0.2626,  ..., -0.0472, -0.3131,  0.0190],\n        [ 0.2811, -0.2875, -0.1179,  ..., -0.3526,  0.1191,  0.1908],\n        ...,\n        [ 0.1634,  0.2225, -0.2164,  ...,  0.1222, -0.0606,  0.2904],\n        [ 0.3353, -0.2209,  0.2938,  ..., -0.0916, -0.1972,  0.2275],\n        [-0.0475,  0.0032,  0.2279,  ..., -0.0646,  0.0437, -0.0329]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0243,  0.0803,  0.2503,  0.0851, -0.3004, -0.3275, -0.0481,  0.2841,\n        -0.0177,  0.3231,  0.2075, -0.1872, -0.1776,  0.0656, -0.1392, -0.0482,\n         0.1686,  0.0535,  0.3090, -0.0431,  0.0915, -0.2558, -0.1086, -0.1365,\n        -0.1367, -0.0295,  0.1250,  0.0432,  0.1687, -0.2725,  0.1635,  0.3199,\n         0.2558, -0.1347, -0.1827,  0.2895,  0.0876, -0.1423, -0.3496,  0.2381,\n        -0.2893, -0.1021, -0.2264, -0.0436, -0.2518,  0.0079,  0.2062,  0.1163,\n         0.2290, -0.1067, -0.0620, -0.1534,  0.0939,  0.1008,  0.1205, -0.0796,\n         0.3432,  0.1593,  0.1492, -0.1777, -0.2868, -0.0531,  0.3070,  0.1192,\n        -0.1672,  0.0717, -0.0876,  0.0413,  0.2249,  0.1353,  0.3130, -0.3282,\n        -0.1706,  0.2766, -0.0944, -0.3228,  0.1386, -0.1641, -0.1741, -0.1194,\n        -0.0930,  0.2033,  0.0097, -0.3477,  0.0270, -0.0562, -0.0197,  0.0755,\n        -0.0594,  0.1486, -0.2716, -0.1870, -0.3089, -0.1436,  0.0502,  0.2866,\n         0.3129,  0.0542,  0.1463, -0.2764, -0.0906, -0.2637,  0.1772,  0.2578,\n        -0.2401,  0.2447, -0.3398,  0.0775, -0.2478,  0.3470, -0.2868, -0.0992,\n         0.2504, -0.2531,  0.0025, -0.0226, -0.3246, -0.1553, -0.3505, -0.0127,\n         0.3314,  0.2870, -0.3066, -0.2647,  0.1555, -0.0097, -0.1899,  0.0263],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0463, -0.0591,  0.0025,  ..., -0.0454,  0.0035,  0.0598],\n        [ 0.0677, -0.0382,  0.0045,  ..., -0.0443, -0.0059, -0.0085],\n        [ 0.0213,  0.0261, -0.0876,  ..., -0.0860,  0.0532,  0.0821],\n        ...,\n        [-0.0032, -0.0758,  0.0682,  ..., -0.0435,  0.0085, -0.0225],\n        [-0.0160,  0.0386, -0.0002,  ..., -0.0131, -0.0426, -0.0119],\n        [-0.0793, -0.0447, -0.0508,  ..., -0.0077, -0.0670,  0.0128]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0507,  0.0322, -0.0754,  0.0183, -0.0360, -0.0019, -0.0443, -0.0270,\n        -0.0108, -0.0817,  0.0116, -0.0640,  0.0154,  0.0031, -0.0456, -0.0468,\n        -0.0732,  0.0792,  0.0711,  0.0715,  0.0767, -0.0301, -0.0455,  0.0726,\n         0.0587, -0.0144, -0.0540,  0.0270,  0.0688,  0.0825, -0.0681,  0.0707,\n        -0.0615, -0.0770,  0.0364,  0.0750,  0.0164, -0.0349,  0.0722,  0.0072,\n         0.0362,  0.0614, -0.0798,  0.0397, -0.0743, -0.0360,  0.0756, -0.0139,\n         0.0639,  0.0119, -0.0184, -0.0077, -0.0703, -0.0217, -0.0612, -0.0412,\n         0.0622, -0.0621,  0.0067,  0.0564,  0.0406, -0.0791, -0.0392, -0.0539,\n         0.0142, -0.0617,  0.0490, -0.0664, -0.0702,  0.0686, -0.0048, -0.0119,\n        -0.0689,  0.0878, -0.0243, -0.0160,  0.0198, -0.0299, -0.0404, -0.0480,\n        -0.0296, -0.0643, -0.0478, -0.0175, -0.0017,  0.0255, -0.0477,  0.0638,\n         0.0662, -0.0604, -0.0064,  0.0355, -0.0470, -0.0115,  0.0426, -0.0783,\n         0.0433,  0.0783, -0.0123, -0.0871, -0.0310,  0.0016,  0.0310,  0.0391,\n        -0.0422,  0.0683, -0.0446,  0.0361, -0.0102,  0.0327,  0.0353,  0.0537,\n         0.0520, -0.0530,  0.0843,  0.0769, -0.0237,  0.0606,  0.0343,  0.0576,\n        -0.0884,  0.0265, -0.0315, -0.0723, -0.0683,  0.0669, -0.0374, -0.0217],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 6.2084e-02, -1.5669e-02,  3.1787e-02, -6.7608e-02,  2.7619e-03,\n          4.1661e-02, -3.4264e-02,  5.5230e-02,  7.9658e-03,  2.0920e-02,\n         -4.2964e-02,  2.0548e-02, -4.0697e-02,  5.8791e-02, -3.6201e-02,\n         -2.8617e-02, -1.6100e-02, -8.5393e-02,  7.4248e-02,  4.7841e-02,\n          4.6021e-02, -6.9631e-02, -5.6546e-02,  5.4073e-02, -4.9203e-02,\n         -4.4036e-02,  1.0897e-02, -4.9033e-02, -4.5477e-02,  4.1485e-02,\n         -5.4938e-02, -2.2462e-02, -1.1506e-02, -3.5880e-02, -7.4979e-02,\n          2.1340e-03, -5.8069e-02, -1.7659e-02,  2.7226e-02,  6.9133e-02,\n          8.2791e-02,  3.7268e-02,  6.8351e-02,  2.3774e-02, -6.8612e-02,\n         -6.2549e-02,  6.3282e-02, -6.2318e-02, -6.5393e-02,  6.6616e-02,\n          2.7113e-02,  2.1753e-02,  7.0283e-02,  7.0385e-02, -6.3161e-02,\n          6.4216e-02, -8.4908e-02,  7.2432e-02, -2.2487e-02,  6.7498e-02,\n         -7.6922e-02,  5.9189e-02, -1.0614e-02, -8.1008e-02,  3.3976e-02,\n          7.7543e-02,  7.3899e-02, -3.3913e-03,  6.1710e-02,  3.4852e-03,\n          4.3505e-02,  2.3675e-02, -1.2804e-03,  8.6422e-02, -4.6302e-02,\n         -4.9508e-02, -8.2463e-02,  7.8091e-02, -5.4860e-02,  2.5327e-02,\n          1.3844e-02,  1.2052e-02, -1.4737e-02, -1.5640e-02,  3.0123e-02,\n          5.2934e-02, -4.6308e-02,  5.2955e-02, -3.5525e-02, -2.6949e-02,\n          3.4942e-02,  6.4518e-02, -1.7398e-02, -8.0376e-02,  4.1644e-02,\n         -6.1177e-02, -3.4092e-02,  1.4145e-03, -1.9815e-02, -1.3084e-02,\n          4.2238e-02,  6.5500e-02,  2.6890e-02, -1.5362e-02, -8.7000e-02,\n          6.7662e-02, -5.8892e-02, -4.7488e-02,  5.7227e-02,  4.5149e-03,\n          3.1263e-02,  1.0062e-02, -1.4017e-02, -7.9147e-02,  3.5260e-03,\n         -1.3418e-02,  2.9276e-02,  6.4896e-02,  6.2517e-02,  5.6328e-03,\n          7.8890e-03,  6.3218e-02,  2.6644e-02,  4.0565e-02,  4.4391e-02,\n          5.1614e-02,  3.3840e-02, -4.5455e-02],\n        [ 1.3704e-02, -2.5036e-02,  5.0004e-02,  4.7009e-02,  7.0663e-02,\n          7.4317e-03, -5.5007e-02, -3.5941e-05, -6.9658e-02,  7.7079e-02,\n         -5.3213e-03,  2.2507e-02, -7.3295e-02,  3.7369e-03,  8.3216e-02,\n          3.2990e-02,  3.2867e-02, -4.1537e-02, -6.9718e-02, -6.5322e-02,\n          5.6118e-02,  7.1257e-02,  4.3885e-02, -2.3315e-02, -4.7161e-02,\n         -7.0837e-02,  8.0373e-02,  6.4823e-02, -4.6669e-02,  8.2509e-02,\n          5.6478e-02,  7.5605e-03,  1.7106e-02, -7.0580e-02,  7.2733e-02,\n         -4.0440e-02, -1.8923e-02, -4.1306e-02, -4.5284e-02, -7.2010e-02,\n         -3.2913e-02, -8.3351e-02, -3.0219e-02, -9.3178e-03, -8.3292e-02,\n          6.6216e-02,  5.7931e-02, -8.8386e-02, -7.2486e-02, -6.2913e-02,\n          4.2495e-03, -2.7838e-02, -1.5118e-02,  2.8442e-02, -2.0445e-02,\n          2.8219e-02, -2.9479e-02,  4.7274e-02,  3.4666e-02, -4.7672e-02,\n         -5.1729e-02,  4.9576e-02,  4.8422e-03,  3.1312e-02,  3.8180e-02,\n          8.3414e-02, -3.1844e-03,  1.7762e-02,  7.7513e-02,  1.4868e-02,\n         -3.2148e-02,  6.5282e-02,  4.0918e-02,  6.8965e-02, -8.9167e-03,\n          1.6965e-02, -6.0856e-02, -7.9060e-02, -4.8410e-02, -1.2906e-02,\n          5.6179e-02, -8.7268e-02,  2.4439e-02, -5.7828e-02,  1.1602e-02,\n          3.2511e-02, -7.1687e-02,  3.6042e-02,  7.4509e-02, -1.1097e-03,\n          2.6040e-02, -5.4684e-02, -7.9055e-02, -5.0928e-02,  8.2165e-02,\n          7.4376e-02,  1.8219e-02,  6.0814e-02, -4.7645e-02,  1.7844e-02,\n         -3.8690e-02, -4.0844e-02,  2.9288e-02, -5.6876e-02,  1.5330e-02,\n         -6.4789e-03,  4.0277e-02,  5.8593e-02, -4.6357e-02, -3.3659e-02,\n          6.1919e-02, -8.5032e-02,  2.1174e-02,  6.8582e-02,  6.8790e-02,\n          6.3338e-03, -2.6793e-02, -8.2767e-02, -1.4321e-02, -2.9088e-02,\n          4.7379e-02,  1.0355e-02,  5.8249e-02,  5.0755e-02, -8.3469e-02,\n          6.2507e-03,  8.7879e-02, -1.5385e-02],\n        [-5.1340e-02, -5.5102e-02,  8.5515e-02,  2.2003e-03, -6.5157e-02,\n         -7.8225e-02, -6.3774e-02,  6.5103e-02, -2.2279e-02, -7.0125e-02,\n         -9.1579e-03,  1.0042e-02, -8.7524e-02,  6.4801e-02, -1.8281e-02,\n         -5.7571e-03,  7.5102e-02,  2.1422e-02, -6.3333e-03,  2.8750e-02,\n          8.1474e-02, -4.1395e-02, -4.7760e-02, -8.1161e-03, -7.5995e-02,\n          7.9259e-02, -3.3109e-02, -7.7702e-02, -1.6830e-02, -4.1954e-03,\n         -8.7677e-02,  7.6787e-02,  4.1088e-02,  3.3570e-02, -1.1606e-02,\n         -4.8050e-03,  7.9279e-02, -6.9391e-02, -4.1300e-03,  4.8070e-02,\n         -6.5278e-02,  8.1190e-03,  3.3248e-03,  7.2857e-02,  5.4420e-02,\n         -5.4175e-03,  7.3901e-02,  2.1976e-02, -6.5352e-02, -2.8824e-02,\n          2.8904e-02, -3.8418e-03, -1.6180e-02,  7.0378e-02, -1.5643e-02,\n          6.0087e-02,  4.4638e-02, -1.8957e-02,  8.7720e-02,  3.1900e-02,\n          4.3299e-02,  6.0298e-02, -2.0954e-02,  8.0065e-02, -1.1930e-02,\n          1.0902e-03, -3.1372e-02,  5.6046e-02, -4.9750e-02,  6.3258e-02,\n          1.7796e-02, -8.5507e-02,  9.8635e-03, -7.8323e-02, -6.7255e-02,\n         -6.2438e-02,  7.3350e-02, -7.9379e-02, -5.5137e-02, -3.9946e-02,\n         -8.8042e-03,  8.1675e-02, -4.8971e-02, -9.7184e-03,  5.6024e-02,\n         -2.6975e-02, -8.7355e-02,  5.7962e-02,  1.2555e-03, -6.7890e-02,\n         -5.4423e-02,  5.9973e-02,  7.1572e-02,  8.7419e-02, -5.9177e-02,\n          2.0758e-02, -3.4664e-02, -1.4289e-02, -2.5261e-02, -8.2891e-02,\n          3.8909e-02, -5.9239e-03, -1.1662e-03, -1.8566e-02, -6.0791e-02,\n          2.4312e-02, -3.4600e-02, -2.5742e-02,  1.3122e-02,  1.5556e-02,\n         -6.5995e-02, -2.5296e-02,  8.1424e-02,  2.5497e-02,  2.9226e-04,\n          1.6112e-02,  5.7190e-02, -4.9218e-02, -2.3537e-02,  8.1652e-02,\n          8.2853e-02,  8.6568e-02,  2.4966e-02,  4.4063e-02, -4.1761e-02,\n         -7.8369e-02, -1.1885e-03,  1.0945e-02],\n        [ 3.6989e-02,  2.1555e-02,  3.8234e-02,  1.0793e-03,  1.3237e-03,\n         -4.7130e-02,  1.3225e-02, -7.4952e-02, -3.1460e-02, -4.0627e-02,\n          4.9254e-02,  3.5126e-02,  2.6323e-02, -1.3786e-02, -1.8741e-02,\n          1.8499e-02,  1.6960e-02,  1.7678e-02,  7.9835e-02,  5.3578e-02,\n         -2.5982e-02,  4.5499e-02, -3.5720e-02,  7.8884e-02, -5.9895e-02,\n          5.1728e-02, -7.9469e-02, -5.4728e-02,  1.1881e-02,  4.4235e-02,\n         -7.6291e-02, -5.6656e-03,  4.1270e-02,  2.6759e-02, -2.8843e-02,\n          2.1647e-02, -2.4473e-02,  5.4683e-02, -4.5143e-02, -7.3449e-02,\n          5.0860e-02,  7.0527e-02, -8.0925e-02,  4.9616e-02,  4.9490e-02,\n         -3.2684e-02, -3.0557e-02,  1.9501e-02,  5.0490e-02,  5.3181e-02,\n         -3.6451e-02,  3.9827e-04,  4.4522e-02, -2.7348e-02, -2.1583e-02,\n          2.1376e-02, -3.2668e-02, -2.5077e-02,  4.6419e-03,  3.7958e-02,\n         -2.6537e-03, -6.5875e-02,  6.6792e-02,  4.1990e-02, -8.2732e-02,\n         -2.1557e-02,  3.5191e-02, -8.8191e-02, -4.5044e-05, -4.3954e-03,\n         -4.6458e-02,  6.8401e-02,  6.1165e-02, -4.5341e-03, -3.6454e-02,\n         -1.9719e-02, -1.3790e-02, -7.2706e-02,  2.3793e-03, -1.7684e-02,\n         -5.0319e-02, -3.9083e-03, -1.9063e-02,  5.0961e-02, -5.8953e-02,\n          1.6805e-02,  4.6212e-02, -5.8697e-02, -2.0214e-02, -2.3974e-02,\n         -1.7035e-02,  5.6136e-02,  7.8574e-02,  8.8095e-02, -1.5326e-02,\n          5.5688e-02, -8.1484e-02,  5.7274e-03,  3.4034e-02,  4.2689e-02,\n         -4.4497e-02,  4.3473e-02, -4.0741e-03, -6.0528e-02,  2.2266e-02,\n          1.8616e-03, -2.0736e-02, -6.3941e-02,  7.4692e-02, -2.4758e-02,\n          4.8486e-02,  1.1482e-02, -2.4229e-02,  4.5149e-02, -3.5286e-02,\n         -3.6196e-02, -3.8491e-02, -7.1034e-02, -1.9946e-02,  5.8083e-02,\n          6.7823e-02,  7.8730e-02,  8.4397e-02, -2.0910e-03,  7.9169e-02,\n         -5.3207e-02,  8.6487e-02, -3.1413e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0329, -0.0148, -0.0064, -0.0586], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<REINFORCE.replay_buffer.ReplayBuffer object at 0x10f712ac0>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	1000000,
                    "gamma":	0.9800000190734863,
                    "lam":	0.9700000286102295,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n ...\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]]",
                    "max_size":	1000000,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "with_vf_baseline":	false
                }
            },
            "_seed":	1,
            "_train_vf_iters":	80,
            "_traj_per_epoch":	8,
            "_vf_lr":	0.0010000000474974513,
            "_with_vf_baseline":	false,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x1558e8850>":	{
                    "epoch_dict":	{},
                    "exp_name":	"relayrl-reinforce-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"././logs/relayrl-reinforce-info/relayrl-reinforce-info_s256470001",
                    "output_file":	{
                        "<_io.TextIOWrapper name='././logs/relayrl-reinforce-info/relayrl-reinforce-info_s256470001/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "save_model_path":	"/Users/tybg/Documents/GitHub/RelayRL-prototype/examples/REINFORCE/box2d/lunar_lander/grpc/server_model.pt"
        }
    }
}