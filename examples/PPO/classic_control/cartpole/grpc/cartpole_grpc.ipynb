{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relayrl_framework import RelayRLAgent, TrainingServer\n",
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cartpole(num_episodes=100, config_path: str = \".\", server_type: str = \"GRPC\"):\n",
    "    env = gym.make('CartPole-v1')\n",
    "    agent = RelayRLAgent(\n",
    "        config_path=config_path,\n",
    "        server_type=server_type\n",
    "    )\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        mask = np.ones(env.action_space.n, dtype=np.float32)\n",
    "        reward = 0.0\n",
    "        while not done:\n",
    "            action_obj = agent.request_for_action(obs, mask, reward)\n",
    "            action_value = int(action_obj.get_act())\n",
    "            next_obs, reward, terminated, truncated, _ = env.step(action_value)\n",
    "            done = terminated or truncated\n",
    "            agent.flag_last_action(reward)\n",
    "            obs = next_obs\n",
    "            total_reward += reward\n",
    "        print(f'#### Episode {episode+1}: Total Reward = {total_reward} ####')\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    buf_size: int = 1000000,\n",
    "    tensorboard: bool = True,\n",
    "    env_dir: str = \".\",\n",
    "    algorithm_dir: str = None,\n",
    "    config_path: str = None,\n",
    "    hyperparams: dict = None,\n",
    "    server_type: str = \"GRPC\",\n",
    "    training_prefix: str = None,\n",
    "    training_host: str = None,\n",
    "    training_port: str = None\n",
    "    ):\n",
    "\n",
    "    _server: TrainingServer = TrainingServer(\n",
    "        algorithm_name=\"PPO\",\n",
    "        obs_dim=4,\n",
    "        act_dim=2,\n",
    "        buf_size=buf_size,\n",
    "        tensorboard=tensorboard,\n",
    "        env_dir=env_dir,\n",
    "        algorithm_dir=algorithm_dir,\n",
    "        config_path=config_path,\n",
    "        hyperparams=hyperparams,\n",
    "        server_type=server_type,\n",
    "        training_prefix=training_prefix,\n",
    "        training_host=training_host,\n",
    "        training_port=training_port\n",
    "    )\n",
    "\n",
    "    train_cartpole(num_episodes=10, config_path=config_path, server_type=server_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ConfigLoader - load_config] Found config.json in current directory: \"relayrl_config.json\"\n",
      "[TrainingServer - new] Resolved configuration path: Some(\"relayrl_config.json\")\n",
      "[TrainingServer - new] Resolved algorithm directory: /Users/tybg/Documents/GitHub/RelayRL-prototype/relayrl_framework/src/native/python/algorithms\n",
      "[Instantiating RelayRL-Framework ZMQ TrainingServer...]\n",
      "[ConfigLoader - load_config] Found config.json in current directory: \"relayrl_config.json\"\n",
      "[TrainingServer - new] Resolved configuration path: relayrl_config.json\n",
      "[TrainingServer - new] Training server address: tcp://127.0.0.1:50051\n",
      "[TrainingServer - new] Trajectory server address: tcp://127.0.0.1:7776\n",
      "[TrainingServer - new] Agent listener address: tcp://127.0.0.1:7777\n",
      "[PythonAlgorithmRequest - new] Initializing Python Algorithm Request...\n",
      "\u001b[32;1mLogging data to ././logs/relayrl-reinforce-info/relayrl-reinforce-info_s388090001/progress.txt\u001b[0m\n",
      "\u001b[36;1mSaving config:\n",
      "\u001b[0m\n",
      "{\n",
      "\"__class__\":\t\"REINFORCE\",\n",
      "\"act_dim\":\t2,\n",
      "\"buf_size\":\t1000000,\n",
      "\"config_loader\":\t\"<builtins.ConfigLoader object at 0x10433aeb0>\",\n",
      "\"config_path\":\t\"relayrl_config.json\",\n",
      "\"env_dir\":\t\".\",\n",
      "\"exp_name\":\t\"relayrl-reinforce-info\",\n",
      "\"hyperparams\":\t{\n",
      "\"discrete\":\ttrue,\n",
      "\"gamma\":\t0.9800000190734863,\n",
      "\"lam\":\t0.9700000286102295,\n",
      "\"pi_lr\":\t0.0003000000142492354,\n",
      "\"seed\":\t1,\n",
      "\"train_vf_iters\":\t80,\n",
      "\"traj_per_epoch\":\t8,\n",
      "\"vf_lr\":\t0.0010000000474974513,\n",
      "\"with_vf_baseline\":\tfalse\n",
      "},\n",
      "\"log_data_dir\":\t\"././logs/\",\n",
      "\"logger_kwargs\":\t{\n",
      "\"exp_name\":\t\"relayrl-reinforce-info\",\n",
      "\"output_dir\":\t\"././logs/relayrl-reinforce-info/relayrl-reinforce-info_s388090001\"\n",
      "},\n",
      "\"obs_dim\":\t4,\n",
      "\"seed\":\t388090001,\n",
      "\"self\":\t{\n",
      "\"<REINFORCE.REINFORCE.REINFORCE object at 0x10435fc70>\":\t{\n",
      "\"_discrete\":\ttrue,\n",
      "\"_gamma\":\t0.9800000190734863,\n",
      "\"_lam\":\t0.9700000286102295,\n",
      "\"_model\":\t{\n",
      "\"PolicyWithoutBaseline(\\n  (policy): DiscretePolicyNetwork(\\n    (pi_network): Sequential(\\n      (0): Linear(in_features=4, out_features=128, bias=True)\\n      (1): ReLU()\\n      (2): Linear(in_features=128, out_features=128, bias=True)\\n      (3): ReLU()\\n      (4): Linear(in_features=128, out_features=2, bias=True)\\n    )\\n  )\\n)\":\t{\n",
      "\"_backward_hooks\":\t{},\n",
      "\"_backward_pre_hooks\":\t{},\n",
      "\"_buffers\":\t{},\n",
      "\"_forward_hooks\":\t{},\n",
      "\"_forward_hooks_always_called\":\t{},\n",
      "\"_forward_hooks_with_kwargs\":\t{},\n",
      "\"_forward_pre_hooks\":\t{},\n",
      "\"_forward_pre_hooks_with_kwargs\":\t{},\n",
      "\"_is_full_backward_hook\":\tnull,\n",
      "\"_load_state_dict_post_hooks\":\t{},\n",
      "\"_load_state_dict_pre_hooks\":\t{},\n",
      "\"_modules\":\t{\n",
      "\"policy\":\t{\n",
      "\"DiscretePolicyNetwork(\\n  (pi_network): Sequential(\\n    (0): Linear(in_features=4, out_features=128, bias=True)\\n    (1): ReLU()\\n    (2): Linear(in_features=128, out_features=128, bias=True)\\n    (3): ReLU()\\n    (4): Linear(in_features=128, out_features=2, bias=True)\\n  )\\n)\":\t{\n",
      "\"_backward_hooks\":\t{},\n",
      "\"_backward_pre_hooks\":\t{},\n",
      "\"_buffers\":\t{},\n",
      "\"_forward_hooks\":\t{},\n",
      "\"_forward_hooks_always_called\":\t{},\n",
      "\"_forward_hooks_with_kwargs\":\t{},\n",
      "\"_forward_pre_hooks\":\t{},\n",
      "\"_forward_pre_hooks_with_kwargs\":\t{},\n",
      "\"_is_full_backward_hook\":\tnull,\n",
      "\"_load_state_dict_post_hooks\":\t{},\n",
      "\"_load_state_dict_pre_hooks\":\t{},\n",
      "\"_modules\":\t{\n",
      "\"pi_network\":\t{\n",
      "\"Sequential(\\n  (0): Linear(in_features=4, out_features=128, bias=True)\\n  (1): ReLU()\\n  (2): Linear(in_features=128, out_features=128, bias=True)\\n  (3): ReLU()\\n  (4): Linear(in_features=128, out_features=2, bias=True)\\n)\":\t{\n",
      "\"_backward_hooks\":\t{},\n",
      "\"_backward_pre_hooks\":\t{},\n",
      "\"_buffers\":\t{},\n",
      "\"_forward_hooks\":\t{},\n",
      "\"_forward_hooks_always_called\":\t{},\n",
      "\"_forward_hooks_with_kwargs\":\t{},\n",
      "\"_forward_pre_hooks\":\t{},\n",
      "\"_forward_pre_hooks_with_kwargs\":\t{},\n",
      "\"_is_full_backward_hook\":\tnull,\n",
      "\"_load_state_dict_post_hooks\":\t{},\n",
      "\"_load_state_dict_pre_hooks\":\t{},\n",
      "\"_modules\":\t{\n",
      "\"0\":\t{\n",
      "\"Linear(in_features=4, out_features=128, bias=True)\":\t{\n",
      "\"_backward_hooks\":\t{},\n",
      "\"_backward_pre_hooks\":\t{},\n",
      "\"_buffers\":\t{},\n",
      "\"_forward_hooks\":\t{},\n",
      "\"_forward_hooks_always_called\":\t{},\n",
      "\"_forward_hooks_with_kwargs\":\t{},\n",
      "\"_forward_pre_hooks\":\t{},\n",
      "\"_forward_pre_hooks_with_kwargs\":\t{},\n",
      "\"_is_full_backward_hook\":\tnull,\n",
      "\"_load_state_dict_post_hooks\":\t{},\n",
      "\"_load_state_dict_pre_hooks\":\t{},\n",
      "\"_modules\":\t{},\n",
      "\"_non_persistent_buffers_set\":\t\"set()\",\n",
      "\"_parameters\":\t{\n",
      "\"bias\":\t\"Parameter containing:\\ntensor([-0.2152, -0.3947, -0.2765,  0.0555,  0.0747, -0.4863, -0.3552,  0.3958,\\n         0.1957, -0.3867, -0.0801,  0.4363, -0.0954, -0.3995,  0.0684,  0.1101,\\n        -0.3934,  0.1301, -0.2483,  0.2300, -0.2533,  0.4706, -0.2315, -0.2032,\\n        -0.2678, -0.2323,  0.0094, -0.0147,  0.2133,  0.4667,  0.2390, -0.0466,\\n         0.4723,  0.2672, -0.0704, -0.0042, -0.3700, -0.2123,  0.0010,  0.1237,\\n         0.0315, -0.1717, -0.4899, -0.1488,  0.2911, -0.3498, -0.0716, -0.2967,\\n         0.2434,  0.0472, -0.0621, -0.0371,  0.4661, -0.4181,  0.2146, -0.1165,\\n         0.4263, -0.3669, -0.4348, -0.0558, -0.1901,  0.0661,  0.1727, -0.3784,\\n         0.3638, -0.0419, -0.3343,  0.4368, -0.0766,  0.4982,  0.2103, -0.2488,\\n         0.3160,  0.1083,  0.3502, -0.4848, -0.4934, -0.0462, -0.3268, -0.4060,\\n         0.3870,  0.1460, -0.4079,  0.3830, -0.4012,  0.0156, -0.1730,  0.3866,\\n         0.1267, -0.4433,  0.1044, -0.4916, -0.3037, -0.4187, -0.2091, -0.2273,\\n         0.0481,  0.3931, -0.1256,  0.3713, -0.1282,  0.0625, -0.2475, -0.0027,\\n         0.2496,  0.2818,  0.2878, -0.2507,  0.1940, -0.2570, -0.0965, -0.1811,\\n         0.3655, -0.2089, -0.2900, -0.2182, -0.4636, -0.1561,  0.0863, -0.1352,\\n         0.4556, -0.2205,  0.2829, -0.4994, -0.0905,  0.1666,  0.1324, -0.4159],\\n       requires_grad=True)\",\n",
      "\"weight\":\t\"Parameter containing:\\ntensor([[ 3.7650e-01, -3.8657e-01,  2.7998e-01, -4.6289e-01],\\n        [-1.9595e-01,  3.6839e-02, -1.4405e-01, -3.3748e-01],\\n        [ 6.9701e-02, -1.6309e-01,  2.9828e-01, -1.7863e-01],\\n        [ 8.5457e-02, -1.1380e-01,  1.8726e-01, -4.7133e-01],\\n        [-4.0803e-01,  4.4972e-02,  9.4808e-02, -3.9283e-01],\\n        [-3.8443e-01, -1.8517e-01, -4.1571e-01,  6.1201e-02],\\n        [ 2.4272e-01,  4.7629e-02, -4.6451e-01, -2.2216e-01],\\n        [-5.1713e-02, -3.2999e-01, -1.6969e-01,  2.6823e-01],\\n        [ 1.2413e-01, -4.6332e-01, -1.2702e-04,  3.5000e-01],\\n        [ 7.9542e-02, -1.3243e-01, -1.0475e-01,  3.5404e-01],\\n        [ 4.9841e-01,  5.9728e-02, -1.2208e-01, -3.1836e-01],\\n        [ 2.2860e-01, -4.5546e-01,  2.2237e-01, -8.8771e-02],\\n        [ 1.0223e-01, -3.5217e-01,  9.3084e-02,  4.1015e-01],\\n        [-1.8095e-01,  8.9387e-02,  1.6292e-01, -2.5139e-01],\\n        [ 9.3039e-02,  3.5978e-01,  3.3725e-02,  4.0399e-01],\\n        [-1.3644e-01,  3.4460e-01,  4.6846e-01,  3.5754e-01],\\n        [-2.3564e-01, -2.8881e-01, -2.9472e-01,  1.7325e-01],\\n        [-2.2380e-01, -4.2226e-01, -1.2787e-01, -1.6334e-01],\\n        [-8.7888e-02,  1.5575e-01,  7.7501e-03, -7.6814e-02],\\n        [ 2.7706e-01, -9.4694e-02, -4.3317e-01,  5.3372e-02],\\n        [-2.4198e-01,  1.8676e-01,  2.7682e-01,  8.0079e-02],\\n        [ 3.8711e-01,  3.9178e-02,  3.5826e-01,  3.9548e-02],\\n        [ 3.4298e-01, -4.9407e-01, -3.3006e-01, -3.3623e-01],\\n        [ 7.1338e-02, -9.8282e-04, -3.9241e-03, -4.1499e-01],\\n        [-2.0914e-01, -3.4444e-01,  5.9937e-02,  1.8750e-01],\\n        [-1.4238e-01, -1.5228e-01,  2.9837e-01,  6.5441e-02],\\n        [ 1.3546e-01, -4.5877e-01, -2.1311e-01, -4.6760e-01],\\n        [ 3.1507e-01,  2.1820e-01, -2.4092e-01, -4.5492e-01],\\n        [ 3.2212e-01, -8.9394e-02,  2.4247e-01,  2.8432e-01],\\n        [-1.1666e-02, -3.6850e-02,  3.3356e-01, -8.3277e-02],\\n        [ 3.6762e-01,  1.3827e-01, -2.6579e-01,  3.9068e-02],\\n        [-4.9720e-01,  8.6110e-02,  2.2322e-01,  4.7276e-01],\\n        [-3.5409e-01, -1.3131e-01, -1.9985e-02, -4.1795e-01],\\n        [-1.6785e-01,  2.6252e-01, -3.4232e-01,  2.4479e-01],\\n        [-2.8381e-01,  1.2482e-02, -2.8664e-01,  3.8853e-01],\\n        [-9.2800e-02,  4.8441e-01, -3.0624e-01, -4.0031e-01],\\n        [-4.9611e-01,  3.3846e-01,  3.0025e-01, -2.8172e-01],\\n        [ 3.0303e-01,  3.5158e-01, -2.8379e-01, -2.9819e-01],\\n        [ 1.5730e-01,  1.2258e-01,  9.8773e-02,  6.3620e-02],\\n        [ 2.3437e-01, -2.4834e-01, -6.8602e-02, -2.4604e-01],\\n        [-1.5278e-01, -2.0329e-02, -3.7409e-01, -2.4038e-01],\\n        [-2.5846e-01, -9.8167e-02, -3.5449e-01, -3.8808e-01],\\n        [-6.4672e-02, -4.8091e-01,  3.6271e-01,  1.9233e-01],\\n        [-4.1045e-01, -1.5817e-01,  1.5370e-01, -5.5298e-02],\\n        [ 1.5279e-01, -4.7214e-01, -1.4291e-01, -2.7555e-01],\\n        [-2.7923e-01,  4.9731e-01,  6.4158e-02, -2.0779e-01],\\n        [ 3.7556e-01, -4.8762e-02, -6.3434e-02, -4.6075e-01],\\n        [ 4.3582e-01,  1.3707e-01,  9.4729e-02, -3.0045e-01],\\n        [-6.1599e-02,  4.0348e-01, -4.3523e-02,  3.7839e-01],\\n        [ 5.4569e-03,  2.3566e-01, -2.7415e-01, -3.5633e-01],\\n        [-1.5508e-01,  3.9853e-01,  2.0624e-01, -3.2769e-01],\\n        [-2.3175e-01,  3.2863e-02, -1.4627e-01,  2.1766e-01],\\n        [-1.2548e-01,  2.8631e-01,  5.9857e-02, -2.6306e-01],\\n        [-3.4708e-01, -3.2086e-01, -4.6495e-01, -2.0772e-01],\\n        [ 1.3799e-02, -2.3251e-01,  2.4514e-01, -1.7209e-01],\\n        [ 4.2319e-01, -2.5718e-01,  3.9567e-01, -1.4277e-01],\\n        [-4.3956e-01,  1.1191e-01, -1.0932e-02, -1.2886e-01],\\n        [-4.2239e-01,  4.4430e-01,  1.5595e-02, -6.2779e-03],\\n        [ 2.9302e-01,  1.4534e-01,  7.0846e-02,  4.8786e-01],\\n        [ 4.4132e-02, -3.5488e-01, -2.9065e-01, -3.8663e-01],\\n        [-1.2180e-01, -1.5995e-01,  2.3107e-01,  1.3313e-01],\\n        [ 2.9737e-01, -8.9157e-02,  1.1523e-01, -3.4244e-01],\\n        [ 7.2213e-02,  4.4092e-01, -3.5455e-01,  2.2933e-01],\\n        [ 4.8681e-01,  8.0219e-02, -9.1857e-02,  3.3759e-01],\\n        [ 1.8733e-01, -3.4923e-01, -2.8916e-01,  3.3928e-01],\\n        [ 3.7230e-02, -4.9701e-01,  3.7333e-02,  1.8618e-02],\\n        [ 4.0399e-01,  4.9555e-01,  4.1508e-01, -2.9148e-01],\\n        [ 4.8999e-01,  4.3146e-01, -4.0504e-01, -8.4209e-02],\\n        [ 3.3106e-01,  3.2394e-01, -7.2909e-02,  3.9102e-02],\\n        [ 4.2379e-01,  1.6041e-01, -4.9330e-01,  2.6539e-01],\\n        [-1.6289e-01,  8.6744e-02,  3.2596e-01, -3.6204e-01],\\n        [ 3.3261e-01, -3.7250e-01, -1.6923e-01, -3.7165e-01],\\n        [ 3.6225e-02, -8.6857e-03, -3.7786e-01,  4.9914e-01],\\n        [ 3.7934e-01, -4.8583e-01, -5.5924e-02, -3.9943e-01],\\n        [ 2.2335e-01,  2.7622e-01,  7.3623e-02, -2.3634e-01],\\n        [ 1.5126e-01,  2.9749e-01,  2.5717e-01, -2.0648e-01],\\n        [ 4.5918e-01,  2.2580e-01, -3.6595e-01, -2.8359e-01],\\n        [ 4.2235e-01, -8.4977e-02, -4.7226e-01,  3.1921e-01],\\n        [ 1.0294e-01, -8.3013e-02,  1.5600e-01,  2.0660e-01],\\n        [ 2.5725e-01,  3.7914e-01, -2.8678e-02,  1.8287e-01],\\n        [-1.7619e-01,  2.9484e-01,  4.3209e-01, -3.0783e-01],\\n        [-3.3352e-02,  1.6082e-01, -2.1524e-01,  2.1189e-01],\\n        [-1.1683e-01, -6.7756e-02,  5.0074e-02,  2.0921e-01],\\n        [-1.6730e-01,  6.5013e-02,  1.6240e-01,  2.9423e-01],\\n        [-1.9399e-02,  3.2167e-01, -4.3430e-01, -2.0234e-01],\\n        [ 3.7684e-01, -2.0863e-01, -2.5915e-01, -3.7451e-01],\\n        [ 4.1569e-01, -3.8578e-01, -5.1876e-02,  2.4455e-01],\\n        [-9.2804e-02, -2.1132e-01,  1.4045e-01, -4.9136e-01],\\n        [-3.4234e-01,  4.1371e-01, -1.6966e-01, -3.8739e-01],\\n        [ 2.5129e-01, -1.2479e-01,  2.3719e-01, -2.4652e-01],\\n        [ 4.7389e-01,  3.6192e-01,  1.8607e-01,  2.5658e-01],\\n        [ 1.1355e-01,  3.8000e-01,  2.0193e-01,  1.0083e-01],\\n        [-4.1616e-01,  9.9739e-02, -4.0222e-01,  8.2493e-02],\\n        [ 2.5955e-01, -4.0672e-01,  4.1273e-01, -2.3167e-01],\\n        [ 8.0509e-03,  3.8051e-01, -4.3532e-01, -2.2744e-01],\\n        [ 2.3710e-01, -2.2666e-01,  1.9674e-01,  1.2795e-01],\\n        [ 1.1091e-01, -1.1500e-01,  3.3727e-02,  2.2182e-01],\\n        [-5.6384e-03,  2.4747e-01,  7.8809e-02, -5.7225e-03],\\n        [-3.1339e-01, -1.4816e-01, -2.6646e-01,  4.1561e-01],\\n        [-2.5980e-01, -9.7967e-02,  3.3324e-01, -3.4008e-01],\\n        [ 1.4094e-01, -4.4335e-01,  1.0989e-01,  2.4214e-01],\\n        [-4.3732e-01, -2.5898e-01, -1.7592e-01,  1.9522e-01],\\n        [-1.7036e-01,  3.6606e-01, -2.3232e-02, -2.1709e-02],\\n        [ 3.6808e-01, -4.2516e-01,  9.1816e-03, -3.9847e-01],\\n        [-3.6037e-01,  1.1458e-01, -2.1640e-01,  3.6617e-01],\\n        [-4.2457e-01, -9.3818e-02,  2.9392e-01,  3.6624e-01],\\n        [ 1.3017e-01,  3.0295e-01,  1.0583e-01,  3.1058e-01],\\n        [-4.0352e-01,  3.2909e-01, -3.6633e-01, -3.4437e-01],\\n        [ 2.4937e-01,  1.1364e-02,  3.5197e-01,  4.7604e-01],\\n        [ 7.9328e-02, -2.6951e-01,  2.6892e-01, -2.5662e-01],\\n        [-3.0069e-01,  3.2536e-01, -2.9856e-01,  3.3277e-02],\\n        [ 1.6756e-01, -7.4536e-02, -4.4203e-02, -3.8847e-01],\\n        [ 4.4111e-01, -6.9277e-03,  1.4155e-01, -3.0173e-01],\\n        [ 1.6189e-01,  5.4767e-02,  2.1240e-02, -1.0251e-01],\\n        [-4.0281e-02,  2.1415e-01,  1.5358e-01,  4.9755e-01],\\n        [ 3.7011e-02,  4.6432e-01,  4.2308e-01,  1.7396e-01],\\n        [-4.1803e-01, -3.0833e-01, -4.9183e-01,  4.1467e-01],\\n        [-3.8361e-01, -2.2769e-01,  4.8297e-01,  4.3129e-01],\\n        [-4.3420e-01,  1.7319e-01,  4.6689e-01,  3.3607e-02],\\n        [ 2.3724e-01,  7.5454e-02, -2.2846e-01,  1.3085e-01],\\n        [ 4.6675e-01,  2.9124e-01, -2.4905e-01, -4.3477e-01],\\n        [-2.8380e-01, -1.3121e-01,  2.5457e-01, -7.7158e-02],\\n        [-5.7672e-02,  1.4934e-01,  1.6187e-01,  2.5155e-01],\\n        [ 1.0112e-01,  4.0934e-01, -3.8197e-01, -2.0317e-01],\\n        [-2.5158e-01, -2.8906e-01, -4.0172e-01,  1.1574e-02],\\n        [ 1.6922e-01, -1.7096e-01,  4.6526e-01, -1.4994e-01],\\n        [-2.9736e-01,  3.9447e-02, -3.4225e-01,  4.2753e-01],\\n        [-1.0112e-02, -2.6983e-01,  4.6449e-01, -1.7327e-01]],\\n       requires_grad=True)\"\n",
      "},\n",
      "\"_state_dict_hooks\":\t{},\n",
      "\"_state_dict_pre_hooks\":\t{},\n",
      "\"in_features\":\t4,\n",
      "\"out_features\":\t128,\n",
      "\"training\":\ttrue\n",
      "}\n",
      "},\n",
      "\"1\":\t{\n",
      "\"ReLU()\":\t{\n",
      "\"_backward_hooks\":\t{},\n",
      "\"_backward_pre_hooks\":\t{},\n",
      "\"_buffers\":\t{},\n",
      "\"_forward_hooks\":\t{},\n",
      "\"_forward_hooks_always_called\":\t{},\n",
      "\"_forward_hooks_with_kwargs\":\t{},\n",
      "\"_forward_pre_hooks\":\t{},\n",
      "\"_forward_pre_hooks_with_kwargs\":\t{},\n",
      "\"_is_full_backward_hook\":\tnull,\n",
      "\"_load_state_dict_post_hooks\":\t{},\n",
      "\"_load_state_dict_pre_hooks\":\t{},\n",
      "\"_modules\":\t{},\n",
      "\"_non_persistent_buffers_set\":\t\"set()\",\n",
      "\"_parameters\":\t{},\n",
      "\"_state_dict_hooks\":\t{},\n",
      "\"_state_dict_pre_hooks\":\t{},\n",
      "\"inplace\":\tfalse,\n",
      "\"training\":\ttrue\n",
      "}\n",
      "},\n",
      "\"2\":\t{\n",
      "\"Linear(in_features=128, out_features=128, bias=True)\":\t{\n",
      "\"_backward_hooks\":\t{},\n",
      "\"_backward_pre_hooks\":\t{},\n",
      "\"_buffers\":\t{},\n",
      "\"_forward_hooks\":\t{},\n",
      "\"_forward_hooks_always_called\":\t{},\n",
      "\"_forward_hooks_with_kwargs\":\t{},\n",
      "\"_forward_pre_hooks\":\t{},\n",
      "\"_forward_pre_hooks_with_kwargs\":\t{},\n",
      "\"_is_full_backward_hook\":\tnull,\n",
      "\"_load_state_dict_post_hooks\":\t{},\n",
      "\"_load_state_dict_pre_hooks\":\t{},\n",
      "\"_modules\":\t{},\n",
      "\"_non_persistent_buffers_set\":\t\"set()\",\n",
      "\"_parameters\":\t{\n",
      "\"bias\":\t\"Parameter containing:\\ntensor([ 0.0293, -0.0650, -0.0309,  0.0111,  0.0111,  0.0634, -0.0082, -0.0639,\\n        -0.0206,  0.0258, -0.0420, -0.0768, -0.0700, -0.0460,  0.0799, -0.0883,\\n         0.0029, -0.0359,  0.0460, -0.0369,  0.0743, -0.0352,  0.0612,  0.0700,\\n         0.0534,  0.0354, -0.0109, -0.0374, -0.0624,  0.0223,  0.0431,  0.0593,\\n         0.0809, -0.0619, -0.0742, -0.0238, -0.0620,  0.0166,  0.0042, -0.0192,\\n        -0.0392, -0.0711, -0.0174,  0.0807,  0.0171, -0.0729, -0.0252,  0.0154,\\n        -0.0315, -0.0762, -0.0757, -0.0721, -0.0764, -0.0618,  0.0855,  0.0240,\\n         0.0504,  0.0352, -0.0048,  0.0719, -0.0665, -0.0737, -0.0251,  0.0370,\\n         0.0677,  0.0050,  0.0129, -0.0329, -0.0638, -0.0686,  0.0266,  0.0782,\\n        -0.0379, -0.0305,  0.0009, -0.0684, -0.0179,  0.0453,  0.0230, -0.0254,\\n        -0.0412,  0.0407,  0.0305, -0.0142,  0.0641,  0.0180,  0.0406, -0.0293,\\n         0.0127, -0.0164, -0.0343, -0.0372, -0.0294,  0.0369,  0.0521,  0.0359,\\n         0.0706, -0.0283,  0.0052,  0.0646,  0.0634, -0.0795, -0.0594, -0.0063,\\n         0.0667, -0.0787,  0.0054, -0.0151,  0.0477, -0.0153, -0.0851, -0.0333,\\n        -0.0676, -0.0148, -0.0582, -0.0247,  0.0764,  0.0318,  0.0475, -0.0416,\\n        -0.0492, -0.0554, -0.0015, -0.0874, -0.0336, -0.0169,  0.0237, -0.0680],\\n       requires_grad=True)\",\n",
      "\"weight\":\t\"Parameter containing:\\ntensor([[-0.0056, -0.0260,  0.0544,  ...,  0.0424,  0.0297, -0.0455],\\n        [ 0.0276, -0.0320,  0.0793,  ..., -0.0820, -0.0608,  0.0474],\\n        [-0.0266, -0.0121,  0.0477,  ..., -0.0852, -0.0244,  0.0592],\\n        ...,\\n        [ 0.0409,  0.0601,  0.0086,  ...,  0.0363,  0.0014, -0.0061],\\n        [ 0.0444,  0.0613,  0.0731,  ...,  0.0248, -0.0317, -0.0458],\\n        [ 0.0239, -0.0381, -0.0741,  ..., -0.0244,  0.0713, -0.0838]],\\n       requires_grad=True)\"\n",
      "},\n",
      "\"_state_dict_hooks\":\t{},\n",
      "\"_state_dict_pre_hooks\":\t{},\n",
      "\"in_features\":\t128,\n",
      "\"out_features\":\t128,\n",
      "\"training\":\ttrue\n",
      "}\n",
      "},\n",
      "\"3\":\t{\n",
      "\"ReLU()\":\t{\n",
      "\"_backward_hooks\":\t{},\n",
      "\"_backward_pre_hooks\":\t{},\n",
      "\"_buffers\":\t{},\n",
      "\"_forward_hooks\":\t{},\n",
      "\"_forward_hooks_always_called\":\t{},\n",
      "\"_forward_hooks_with_kwargs\":\t{},\n",
      "\"_forward_pre_hooks\":\t{},\n",
      "\"_forward_pre_hooks_with_kwargs\":\t{},\n",
      "\"_is_full_backward_hook\":\tnull,\n",
      "\"_load_state_dict_post_hooks\":\t{},\n",
      "\"_load_state_dict_pre_hooks\":\t{},\n",
      "\"_modules\":\t{},\n",
      "\"_non_persistent_buffers_set\":\t\"set()\",\n",
      "\"_parameters\":\t{},\n",
      "\"_state_dict_hooks\":\t{},\n",
      "\"_state_dict_pre_hooks\":\t{},\n",
      "\"inplace\":\tfalse,\n",
      "\"training\":\ttrue\n",
      "}\n",
      "},\n",
      "\"4\":\t{\n",
      "\"Linear(in_features=128, out_features=2, bias=True)\":\t{\n",
      "\"_backward_hooks\":\t{},\n",
      "\"_backward_pre_hooks\":\t{},\n",
      "\"_buffers\":\t{},\n",
      "\"_forward_hooks\":\t{},\n",
      "\"_forward_hooks_always_called\":\t{},\n",
      "\"_forward_hooks_with_kwargs\":\t{},\n",
      "\"_forward_pre_hooks\":\t{},\n",
      "\"_forward_pre_hooks_with_kwargs\":\t{},\n",
      "\"_is_full_backward_hook\":\tnull,\n",
      "\"_load_state_dict_post_hooks\":\t{},\n",
      "\"_load_state_dict_pre_hooks\":\t{},\n",
      "\"_modules\":\t{},\n",
      "\"_non_persistent_buffers_set\":\t\"set()\",\n",
      "\"_parameters\":\t{\n",
      "\"bias\":\t\"Parameter containing:\\ntensor([-0.0418,  0.0837], requires_grad=True)\",\n",
      "\"weight\":\t\"Parameter containing:\\ntensor([[-0.0415,  0.0291,  0.0145,  0.0121,  0.0800,  0.0039, -0.0716, -0.0121,\\n         -0.0215,  0.0189,  0.0101,  0.0513, -0.0782, -0.0762,  0.0738,  0.0132,\\n          0.0222,  0.0797,  0.0770,  0.0506, -0.0877, -0.0126, -0.0298,  0.0834,\\n          0.0610,  0.0099,  0.0142,  0.0650, -0.0544, -0.0695, -0.0425, -0.0589,\\n         -0.0238, -0.0587,  0.0629,  0.0861,  0.0500,  0.0268, -0.0600,  0.0831,\\n         -0.0171, -0.0817, -0.0422, -0.0717, -0.0612, -0.0596,  0.0536,  0.0151,\\n          0.0472, -0.0417, -0.0534,  0.0286,  0.0187,  0.0872, -0.0250, -0.0184,\\n          0.0316,  0.0606, -0.0865, -0.0805,  0.0252,  0.0325,  0.0165, -0.0616,\\n         -0.0229,  0.0803,  0.0434, -0.0469,  0.0428,  0.0402,  0.0497, -0.0379,\\n         -0.0111,  0.0340,  0.0675,  0.0576,  0.0635,  0.0836, -0.0041,  0.0002,\\n          0.0787, -0.0521,  0.0784,  0.0230,  0.0534, -0.0641, -0.0149,  0.0689,\\n          0.0827,  0.0198, -0.0789,  0.0722,  0.0178, -0.0441, -0.0428,  0.0815,\\n          0.0078, -0.0569,  0.0854, -0.0126, -0.0187,  0.0098, -0.0513,  0.0511,\\n         -0.0869, -0.0576,  0.0723, -0.0826,  0.0699,  0.0831, -0.0686, -0.0339,\\n         -0.0067,  0.0043, -0.0029,  0.0177,  0.0729,  0.0479, -0.0173, -0.0171,\\n         -0.0138,  0.0554, -0.0597,  0.0505, -0.0477, -0.0739, -0.0052,  0.0399],\\n        [ 0.0525,  0.0652,  0.0176, -0.0228, -0.0571,  0.0135,  0.0847, -0.0029,\\n         -0.0272, -0.0736, -0.0680,  0.0589,  0.0808,  0.0399,  0.0301, -0.0561,\\n          0.0609, -0.0839, -0.0117,  0.0498,  0.0434,  0.0733,  0.0476, -0.0800,\\n          0.0506,  0.0547,  0.0439, -0.0092,  0.0264,  0.0702, -0.0536,  0.0656,\\n         -0.0602, -0.0271,  0.0461, -0.0027, -0.0868, -0.0463,  0.0443, -0.0401,\\n          0.0552, -0.0204, -0.0729, -0.0697,  0.0187, -0.0072, -0.0011, -0.0535,\\n          0.0130,  0.0710, -0.0723, -0.0804,  0.0149,  0.0880, -0.0010, -0.0180,\\n          0.0012,  0.0388, -0.0343,  0.0871,  0.0862, -0.0716,  0.0274,  0.0487,\\n         -0.0865, -0.0792,  0.0495,  0.0418,  0.0447,  0.0725,  0.0765,  0.0152,\\n         -0.0321, -0.0579, -0.0018,  0.0699,  0.0295, -0.0822,  0.0052,  0.0240,\\n          0.0169,  0.0863,  0.0120, -0.0849,  0.0718, -0.0039, -0.0247, -0.0290,\\n         -0.0465,  0.0421,  0.0334, -0.0485, -0.0700, -0.0458,  0.0417,  0.0704,\\n          0.0495,  0.0500,  0.0497,  0.0106, -0.0316,  0.0572,  0.0711,  0.0095,\\n         -0.0032,  0.0843, -0.0205,  0.0556, -0.0387,  0.0623,  0.0139,  0.0691,\\n         -0.0594,  0.0093,  0.0543,  0.0112, -0.0063,  0.0037, -0.0452,  0.0243,\\n          0.0234, -0.0588, -0.0252, -0.0451, -0.0269, -0.0094, -0.0313, -0.0606]],\\n       requires_grad=True)\"\n",
      "},\n",
      "\"_state_dict_hooks\":\t{},\n",
      "\"_state_dict_pre_hooks\":\t{},\n",
      "\"in_features\":\t128,\n",
      "\"out_features\":\t2,\n",
      "\"training\":\ttrue\n",
      "}\n",
      "}\n",
      "},\n",
      "\"_non_persistent_buffers_set\":\t\"set()\",\n",
      "\"_parameters\":\t{},\n",
      "\"_state_dict_hooks\":\t{},\n",
      "\"_state_dict_pre_hooks\":\t{},\n",
      "\"training\":\ttrue\n",
      "}\n",
      "}\n",
      "},\n",
      "\"_non_persistent_buffers_set\":\t\"set()\",\n",
      "\"_parameters\":\t{},\n",
      "\"_state_dict_hooks\":\t{},\n",
      "\"_state_dict_pre_hooks\":\t{},\n",
      "\"training\":\ttrue\n",
      "}\n",
      "}\n",
      "},\n",
      "\"_non_persistent_buffers_set\":\t\"set()\",\n",
      "\"_parameters\":\t{},\n",
      "\"_state_dict_hooks\":\t{},\n",
      "\"_state_dict_pre_hooks\":\t{},\n",
      "\"custom_network\":\tnull,\n",
      "\"input_dim\":\t4,\n",
      "\"output_dim\":\t2,\n",
      "\"training\":\ttrue\n",
      "}\n",
      "},\n",
      "\"_pi_lr\":\t0.0003000000142492354,\n",
      "\"_pi_optimizer\":\t{\n",
      "\"Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    lr: 0.0003000000142492354\\n    maximize: False\\n    weight_decay: 0\\n)\":\t{\n",
      "\"_optimizer_load_state_dict_post_hooks\":\t{},\n",
      "\"_optimizer_load_state_dict_pre_hooks\":\t{},\n",
      "\"_optimizer_state_dict_post_hooks\":\t{},\n",
      "\"_optimizer_state_dict_pre_hooks\":\t{},\n",
      "\"_optimizer_step_post_hooks\":\t{},\n",
      "\"_optimizer_step_pre_hooks\":\t{},\n",
      "\"_warned_capturable_if_run_uncaptured\":\ttrue,\n",
      "\"_zero_grad_profile_name\":\t\"Optimizer.zero_grad#Adam.zero_grad\",\n",
      "\"defaults\":\t{\n",
      "\"amsgrad\":\tfalse,\n",
      "\"betas\":\t[\n",
      "0.9,\n",
      "0.999\n",
      "],\n",
      "\"capturable\":\tfalse,\n",
      "\"differentiable\":\tfalse,\n",
      "\"eps\":\t1e-08,\n",
      "\"foreach\":\tnull,\n",
      "\"fused\":\tnull,\n",
      "\"lr\":\t0.0003000000142492354,\n",
      "\"maximize\":\tfalse,\n",
      "\"weight_decay\":\t0\n",
      "},\n",
      "\"param_groups\":\t[\n",
      "{\n",
      "\"amsgrad\":\tfalse,\n",
      "\"betas\":\t[\n",
      "0.9,\n",
      "0.999\n",
      "],\n",
      "\"capturable\":\tfalse,\n",
      "\"differentiable\":\tfalse,\n",
      "\"eps\":\t1e-08,\n",
      "\"foreach\":\tnull,\n",
      "\"fused\":\tnull,\n",
      "\"lr\":\t0.0003000000142492354,\n",
      "\"maximize\":\tfalse,\n",
      "\"params\":\t[\n",
      "\"Parameter containing:\\ntensor([[ 3.7650e-01, -3.8657e-01,  2.7998e-01, -4.6289e-01],\\n        [-1.9595e-01,  3.6839e-02, -1.4405e-01, -3.3748e-01],\\n        [ 6.9701e-02, -1.6309e-01,  2.9828e-01, -1.7863e-01],\\n        [ 8.5457e-02, -1.1380e-01,  1.8726e-01, -4.7133e-01],\\n        [-4.0803e-01,  4.4972e-02,  9.4808e-02, -3.9283e-01],\\n        [-3.8443e-01, -1.8517e-01, -4.1571e-01,  6.1201e-02],\\n        [ 2.4272e-01,  4.7629e-02, -4.6451e-01, -2.2216e-01],\\n        [-5.1713e-02, -3.2999e-01, -1.6969e-01,  2.6823e-01],\\n        [ 1.2413e-01, -4.6332e-01, -1.2702e-04,  3.5000e-01],\\n        [ 7.9542e-02, -1.3243e-01, -1.0475e-01,  3.5404e-01],\\n        [ 4.9841e-01,  5.9728e-02, -1.2208e-01, -3.1836e-01],\\n        [ 2.2860e-01, -4.5546e-01,  2.2237e-01, -8.8771e-02],\\n        [ 1.0223e-01, -3.5217e-01,  9.3084e-02,  4.1015e-01],\\n        [-1.8095e-01,  8.9387e-02,  1.6292e-01, -2.5139e-01],\\n        [ 9.3039e-02,  3.5978e-01,  3.3725e-02,  4.0399e-01],\\n        [-1.3644e-01,  3.4460e-01,  4.6846e-01,  3.5754e-01],\\n        [-2.3564e-01, -2.8881e-01, -2.9472e-01,  1.7325e-01],\\n        [-2.2380e-01, -4.2226e-01, -1.2787e-01, -1.6334e-01],\\n        [-8.7888e-02,  1.5575e-01,  7.7501e-03, -7.6814e-02],\\n        [ 2.7706e-01, -9.4694e-02, -4.3317e-01,  5.3372e-02],\\n        [-2.4198e-01,  1.8676e-01,  2.7682e-01,  8.0079e-02],\\n        [ 3.8711e-01,  3.9178e-02,  3.5826e-01,  3.9548e-02],\\n        [ 3.4298e-01, -4.9407e-01, -3.3006e-01, -3.3623e-01],\\n        [ 7.1338e-02, -9.8282e-04, -3.9241e-03, -4.1499e-01],\\n        [-2.0914e-01, -3.4444e-01,  5.9937e-02,  1.8750e-01],\\n        [-1.4238e-01, -1.5228e-01,  2.9837e-01,  6.5441e-02],\\n        [ 1.3546e-01, -4.5877e-01, -2.1311e-01, -4.6760e-01],\\n        [ 3.1507e-01,  2.1820e-01, -2.4092e-01, -4.5492e-01],\\n        [ 3.2212e-01, -8.9394e-02,  2.4247e-01,  2.8432e-01],\\n        [-1.1666e-02, -3.6850e-02,  3.3356e-01, -8.3277e-02],\\n        [ 3.6762e-01,  1.3827e-01, -2.6579e-01,  3.9068e-02],\\n        [-4.9720e-01,  8.6110e-02,  2.2322e-01,  4.7276e-01],\\n        [-3.5409e-01, -1.3131e-01, -1.9985e-02, -4.1795e-01],\\n        [-1.6785e-01,  2.6252e-01, -3.4232e-01,  2.4479e-01],\\n        [-2.8381e-01,  1.2482e-02, -2.8664e-01,  3.8853e-01],\\n        [-9.2800e-02,  4.8441e-01, -3.0624e-01, -4.0031e-01],\\n        [-4.9611e-01,  3.3846e-01,  3.0025e-01, -2.8172e-01],\\n        [ 3.0303e-01,  3.5158e-01, -2.8379e-01, -2.9819e-01],\\n        [ 1.5730e-01,  1.2258e-01,  9.8773e-02,  6.3620e-02],\\n        [ 2.3437e-01, -2.4834e-01, -6.8602e-02, -2.4604e-01],\\n        [-1.5278e-01, -2.0329e-02, -3.7409e-01, -2.4038e-01],\\n        [-2.5846e-01, -9.8167e-02, -3.5449e-01, -3.8808e-01],\\n        [-6.4672e-02, -4.8091e-01,  3.6271e-01,  1.9233e-01],\\n        [-4.1045e-01, -1.5817e-01,  1.5370e-01, -5.5298e-02],\\n        [ 1.5279e-01, -4.7214e-01, -1.4291e-01, -2.7555e-01],\\n        [-2.7923e-01,  4.9731e-01,  6.4158e-02, -2.0779e-01],\\n        [ 3.7556e-01, -4.8762e-02, -6.3434e-02, -4.6075e-01],\\n        [ 4.3582e-01,  1.3707e-01,  9.4729e-02, -3.0045e-01],\\n        [-6.1599e-02,  4.0348e-01, -4.3523e-02,  3.7839e-01],\\n        [ 5.4569e-03,  2.3566e-01, -2.7415e-01, -3.5633e-01],\\n        [-1.5508e-01,  3.9853e-01,  2.0624e-01, -3.2769e-01],\\n        [-2.3175e-01,  3.2863e-02, -1.4627e-01,  2.1766e-01],\\n        [-1.2548e-01,  2.8631e-01,  5.9857e-02, -2.6306e-01],\\n        [-3.4708e-01, -3.2086e-01, -4.6495e-01, -2.0772e-01],\\n        [ 1.3799e-02, -2.3251e-01,  2.4514e-01, -1.7209e-01],\\n        [ 4.2319e-01, -2.5718e-01,  3.9567e-01, -1.4277e-01],\\n        [-4.3956e-01,  1.1191e-01, -1.0932e-02, -1.2886e-01],\\n        [-4.2239e-01,  4.4430e-01,  1.5595e-02, -6.2779e-03],\\n        [ 2.9302e-01,  1.4534e-01,  7.0846e-02,  4.8786e-01],\\n        [ 4.4132e-02, -3.5488e-01, -2.9065e-01, -3.8663e-01],\\n        [-1.2180e-01, -1.5995e-01,  2.3107e-01,  1.3313e-01],\\n        [ 2.9737e-01, -8.9157e-02,  1.1523e-01, -3.4244e-01],\\n        [ 7.2213e-02,  4.4092e-01, -3.5455e-01,  2.2933e-01],\\n        [ 4.8681e-01,  8.0219e-02, -9.1857e-02,  3.3759e-01],\\n        [ 1.8733e-01, -3.4923e-01, -2.8916e-01,  3.3928e-01],\\n        [ 3.7230e-02, -4.9701e-01,  3.7333e-02,  1.8618e-02],\\n        [ 4.0399e-01,  4.9555e-01,  4.1508e-01, -2.9148e-01],\\n        [ 4.8999e-01,  4.3146e-01, -4.0504e-01, -8.4209e-02],\\n        [ 3.3106e-01,  3.2394e-01, -7.2909e-02,  3.9102e-02],\\n        [ 4.2379e-01,  1.6041e-01, -4.9330e-01,  2.6539e-01],\\n        [-1.6289e-01,  8.6744e-02,  3.2596e-01, -3.6204e-01],\\n        [ 3.3261e-01, -3.7250e-01, -1.6923e-01, -3.7165e-01],\\n        [ 3.6225e-02, -8.6857e-03, -3.7786e-01,  4.9914e-01],\\n        [ 3.7934e-01, -4.8583e-01, -5.5924e-02, -3.9943e-01],\\n        [ 2.2335e-01,  2.7622e-01,  7.3623e-02, -2.3634e-01],\\n        [ 1.5126e-01,  2.9749e-01,  2.5717e-01, -2.0648e-01],\\n        [ 4.5918e-01,  2.2580e-01, -3.6595e-01, -2.8359e-01],\\n        [ 4.2235e-01, -8.4977e-02, -4.7226e-01,  3.1921e-01],\\n        [ 1.0294e-01, -8.3013e-02,  1.5600e-01,  2.0660e-01],\\n        [ 2.5725e-01,  3.7914e-01, -2.8678e-02,  1.8287e-01],\\n        [-1.7619e-01,  2.9484e-01,  4.3209e-01, -3.0783e-01],\\n        [-3.3352e-02,  1.6082e-01, -2.1524e-01,  2.1189e-01],\\n        [-1.1683e-01, -6.7756e-02,  5.0074e-02,  2.0921e-01],\\n        [-1.6730e-01,  6.5013e-02,  1.6240e-01,  2.9423e-01],\\n        [-1.9399e-02,  3.2167e-01, -4.3430e-01, -2.0234e-01],\\n        [ 3.7684e-01, -2.0863e-01, -2.5915e-01, -3.7451e-01],\\n        [ 4.1569e-01, -3.8578e-01, -5.1876e-02,  2.4455e-01],\\n        [-9.2804e-02, -2.1132e-01,  1.4045e-01, -4.9136e-01],\\n        [-3.4234e-01,  4.1371e-01, -1.6966e-01, -3.8739e-01],\\n        [ 2.5129e-01, -1.2479e-01,  2.3719e-01, -2.4652e-01],\\n        [ 4.7389e-01,  3.6192e-01,  1.8607e-01,  2.5658e-01],\\n        [ 1.1355e-01,  3.8000e-01,  2.0193e-01,  1.0083e-01],\\n        [-4.1616e-01,  9.9739e-02, -4.0222e-01,  8.2493e-02],\\n        [ 2.5955e-01, -4.0672e-01,  4.1273e-01, -2.3167e-01],\\n        [ 8.0509e-03,  3.8051e-01, -4.3532e-01, -2.2744e-01],\\n        [ 2.3710e-01, -2.2666e-01,  1.9674e-01,  1.2795e-01],\\n        [ 1.1091e-01, -1.1500e-01,  3.3727e-02,  2.2182e-01],\\n        [-5.6384e-03,  2.4747e-01,  7.8809e-02, -5.7225e-03],\\n        [-3.1339e-01, -1.4816e-01, -2.6646e-01,  4.1561e-01],\\n        [-2.5980e-01, -9.7967e-02,  3.3324e-01, -3.4008e-01],\\n        [ 1.4094e-01, -4.4335e-01,  1.0989e-01,  2.4214e-01],\\n        [-4.3732e-01, -2.5898e-01, -1.7592e-01,  1.9522e-01],\\n        [-1.7036e-01,  3.6606e-01, -2.3232e-02, -2.1709e-02],\\n        [ 3.6808e-01, -4.2516e-01,  9.1816e-03, -3.9847e-01],\\n        [-3.6037e-01,  1.1458e-01, -2.1640e-01,  3.6617e-01],\\n        [-4.2457e-01, -9.3818e-02,  2.9392e-01,  3.6624e-01],\\n        [ 1.3017e-01,  3.0295e-01,  1.0583e-01,  3.1058e-01],\\n        [-4.0352e-01,  3.2909e-01, -3.6633e-01, -3.4437e-01],\\n        [ 2.4937e-01,  1.1364e-02,  3.5197e-01,  4.7604e-01],\\n        [ 7.9328e-02, -2.6951e-01,  2.6892e-01, -2.5662e-01],\\n        [-3.0069e-01,  3.2536e-01, -2.9856e-01,  3.3277e-02],\\n        [ 1.6756e-01, -7.4536e-02, -4.4203e-02, -3.8847e-01],\\n        [ 4.4111e-01, -6.9277e-03,  1.4155e-01, -3.0173e-01],\\n        [ 1.6189e-01,  5.4767e-02,  2.1240e-02, -1.0251e-01],\\n        [-4.0281e-02,  2.1415e-01,  1.5358e-01,  4.9755e-01],\\n        [ 3.7011e-02,  4.6432e-01,  4.2308e-01,  1.7396e-01],\\n        [-4.1803e-01, -3.0833e-01, -4.9183e-01,  4.1467e-01],\\n        [-3.8361e-01, -2.2769e-01,  4.8297e-01,  4.3129e-01],\\n        [-4.3420e-01,  1.7319e-01,  4.6689e-01,  3.3607e-02],\\n        [ 2.3724e-01,  7.5454e-02, -2.2846e-01,  1.3085e-01],\\n        [ 4.6675e-01,  2.9124e-01, -2.4905e-01, -4.3477e-01],\\n        [-2.8380e-01, -1.3121e-01,  2.5457e-01, -7.7158e-02],\\n        [-5.7672e-02,  1.4934e-01,  1.6187e-01,  2.5155e-01],\\n        [ 1.0112e-01,  4.0934e-01, -3.8197e-01, -2.0317e-01],\\n        [-2.5158e-01, -2.8906e-01, -4.0172e-01,  1.1574e-02],\\n        [ 1.6922e-01, -1.7096e-01,  4.6526e-01, -1.4994e-01],\\n        [-2.9736e-01,  3.9447e-02, -3.4225e-01,  4.2753e-01],\\n        [-1.0112e-02, -2.6983e-01,  4.6449e-01, -1.7327e-01]],\\n       requires_grad=True)\",\n",
      "\"Parameter containing:\\ntensor([-0.2152, -0.3947, -0.2765,  0.0555,  0.0747, -0.4863, -0.3552,  0.3958,\\n         0.1957, -0.3867, -0.0801,  0.4363, -0.0954, -0.3995,  0.0684,  0.1101,\\n        -0.3934,  0.1301, -0.2483,  0.2300, -0.2533,  0.4706, -0.2315, -0.2032,\\n        -0.2678, -0.2323,  0.0094, -0.0147,  0.2133,  0.4667,  0.2390, -0.0466,\\n         0.4723,  0.2672, -0.0704, -0.0042, -0.3700, -0.2123,  0.0010,  0.1237,\\n         0.0315, -0.1717, -0.4899, -0.1488,  0.2911, -0.3498, -0.0716, -0.2967,\\n         0.2434,  0.0472, -0.0621, -0.0371,  0.4661, -0.4181,  0.2146, -0.1165,\\n         0.4263, -0.3669, -0.4348, -0.0558, -0.1901,  0.0661,  0.1727, -0.3784,\\n         0.3638, -0.0419, -0.3343,  0.4368, -0.0766,  0.4982,  0.2103, -0.2488,\\n         0.3160,  0.1083,  0.3502, -0.4848, -0.4934, -0.0462, -0.3268, -0.4060,\\n         0.3870,  0.1460, -0.4079,  0.3830, -0.4012,  0.0156, -0.1730,  0.3866,\\n         0.1267, -0.4433,  0.1044, -0.4916, -0.3037, -0.4187, -0.2091, -0.2273,\\n         0.0481,  0.3931, -0.1256,  0.3713, -0.1282,  0.0625, -0.2475, -0.0027,\\n         0.2496,  0.2818,  0.2878, -0.2507,  0.1940, -0.2570, -0.0965, -0.1811,\\n         0.3655, -0.2089, -0.2900, -0.2182, -0.4636, -0.1561,  0.0863, -0.1352,\\n         0.4556, -0.2205,  0.2829, -0.4994, -0.0905,  0.1666,  0.1324, -0.4159],\\n       requires_grad=True)\",\n",
      "\"Parameter containing:\\ntensor([[-0.0056, -0.0260,  0.0544,  ...,  0.0424,  0.0297, -0.0455],\\n        [ 0.0276, -0.0320,  0.0793,  ..., -0.0820, -0.0608,  0.0474],\\n        [-0.0266, -0.0121,  0.0477,  ..., -0.0852, -0.0244,  0.0592],\\n        ...,\\n        [ 0.0409,  0.0601,  0.0086,  ...,  0.0363,  0.0014, -0.0061],\\n        [ 0.0444,  0.0613,  0.0731,  ...,  0.0248, -0.0317, -0.0458],\\n        [ 0.0239, -0.0381, -0.0741,  ..., -0.0244,  0.0713, -0.0838]],\\n       requires_grad=True)\",\n",
      "\"Parameter containing:\\ntensor([ 0.0293, -0.0650, -0.0309,  0.0111,  0.0111,  0.0634, -0.0082, -0.0639,\\n        -0.0206,  0.0258, -0.0420, -0.0768, -0.0700, -0.0460,  0.0799, -0.0883,\\n         0.0029, -0.0359,  0.0460, -0.0369,  0.0743, -0.0352,  0.0612,  0.0700,\\n         0.0534,  0.0354, -0.0109, -0.0374, -0.0624,  0.0223,  0.0431,  0.0593,\\n         0.0809, -0.0619, -0.0742, -0.0238, -0.0620,  0.0166,  0.0042, -0.0192,\\n        -0.0392, -0.0711, -0.0174,  0.0807,  0.0171, -0.0729, -0.0252,  0.0154,\\n        -0.0315, -0.0762, -0.0757, -0.0721, -0.0764, -0.0618,  0.0855,  0.0240,\\n         0.0504,  0.0352, -0.0048,  0.0719, -0.0665, -0.0737, -0.0251,  0.0370,\\n         0.0677,  0.0050,  0.0129, -0.0329, -0.0638, -0.0686,  0.0266,  0.0782,\\n        -0.0379, -0.0305,  0.0009, -0.0684, -0.0179,  0.0453,  0.0230, -0.0254,\\n        -0.0412,  0.0407,  0.0305, -0.0142,  0.0641,  0.0180,  0.0406, -0.0293,\\n         0.0127, -0.0164, -0.0343, -0.0372, -0.0294,  0.0369,  0.0521,  0.0359,\\n         0.0706, -0.0283,  0.0052,  0.0646,  0.0634, -0.0795, -0.0594, -0.0063,\\n         0.0667, -0.0787,  0.0054, -0.0151,  0.0477, -0.0153, -0.0851, -0.0333,\\n        -0.0676, -0.0148, -0.0582, -0.0247,  0.0764,  0.0318,  0.0475, -0.0416,\\n        -0.0492, -0.0554, -0.0015, -0.0874, -0.0336, -0.0169,  0.0237, -0.0680],\\n       requires_grad=True)\",\n",
      "\"Parameter containing:\\ntensor([[-0.0415,  0.0291,  0.0145,  0.0121,  0.0800,  0.0039, -0.0716, -0.0121,\\n         -0.0215,  0.0189,  0.0101,  0.0513, -0.0782, -0.0762,  0.0738,  0.0132,\\n          0.0222,  0.0797,  0.0770,  0.0506, -0.0877, -0.0126, -0.0298,  0.0834,\\n          0.0610,  0.0099,  0.0142,  0.0650, -0.0544, -0.0695, -0.0425, -0.0589,\\n         -0.0238, -0.0587,  0.0629,  0.0861,  0.0500,  0.0268, -0.0600,  0.0831,\\n         -0.0171, -0.0817, -0.0422, -0.0717, -0.0612, -0.0596,  0.0536,  0.0151,\\n          0.0472, -0.0417, -0.0534,  0.0286,  0.0187,  0.0872, -0.0250, -0.0184,\\n          0.0316,  0.0606, -0.0865, -0.0805,  0.0252,  0.0325,  0.0165, -0.0616,\\n         -0.0229,  0.0803,  0.0434, -0.0469,  0.0428,  0.0402,  0.0497, -0.0379,\\n         -0.0111,  0.0340,  0.0675,  0.0576,  0.0635,  0.0836, -0.0041,  0.0002,\\n          0.0787, -0.0521,  0.0784,  0.0230,  0.0534, -0.0641, -0.0149,  0.0689,\\n          0.0827,  0.0198, -0.0789,  0.0722,  0.0178, -0.0441, -0.0428,  0.0815,\\n          0.0078, -0.0569,  0.0854, -0.0126, -0.0187,  0.0098, -0.0513,  0.0511,\\n         -0.0869, -0.0576,  0.0723, -0.0826,  0.0699,  0.0831, -0.0686, -0.0339,\\n         -0.0067,  0.0043, -0.0029,  0.0177,  0.0729,  0.0479, -0.0173, -0.0171,\\n         -0.0138,  0.0554, -0.0597,  0.0505, -0.0477, -0.0739, -0.0052,  0.0399],\\n        [ 0.0525,  0.0652,  0.0176, -0.0228, -0.0571,  0.0135,  0.0847, -0.0029,\\n         -0.0272, -0.0736, -0.0680,  0.0589,  0.0808,  0.0399,  0.0301, -0.0561,\\n          0.0609, -0.0839, -0.0117,  0.0498,  0.0434,  0.0733,  0.0476, -0.0800,\\n          0.0506,  0.0547,  0.0439, -0.0092,  0.0264,  0.0702, -0.0536,  0.0656,\\n         -0.0602, -0.0271,  0.0461, -0.0027, -0.0868, -0.0463,  0.0443, -0.0401,\\n          0.0552, -0.0204, -0.0729, -0.0697,  0.0187, -0.0072, -0.0011, -0.0535,\\n          0.0130,  0.0710, -0.0723, -0.0804,  0.0149,  0.0880, -0.0010, -0.0180,\\n          0.0012,  0.0388, -0.0343,  0.0871,  0.0862, -0.0716,  0.0274,  0.0487,\\n         -0.0865, -0.0792,  0.0495,  0.0418,  0.0447,  0.0725,  0.0765,  0.0152,\\n         -0.0321, -0.0579, -0.0018,  0.0699,  0.0295, -0.0822,  0.0052,  0.0240,\\n          0.0169,  0.0863,  0.0120, -0.0849,  0.0718, -0.0039, -0.0247, -0.0290,\\n         -0.0465,  0.0421,  0.0334, -0.0485, -0.0700, -0.0458,  0.0417,  0.0704,\\n          0.0495,  0.0500,  0.0497,  0.0106, -0.0316,  0.0572,  0.0711,  0.0095,\\n         -0.0032,  0.0843, -0.0205,  0.0556, -0.0387,  0.0623,  0.0139,  0.0691,\\n         -0.0594,  0.0093,  0.0543,  0.0112, -0.0063,  0.0037, -0.0452,  0.0243,\\n          0.0234, -0.0588, -0.0252, -0.0451, -0.0269, -0.0094, -0.0313, -0.0606]],\\n       requires_grad=True)\",\n",
      "\"Parameter containing:\\ntensor([-0.0418,  0.0837], requires_grad=True)\"\n",
      "],\n",
      "\"weight_decay\":\t0\n",
      "}\n",
      "],\n",
      "\"state\":\t{}\n",
      "}\n",
      "},\n",
      "\"_replay_buffer\":\t{\n",
      "\"<REINFORCE.replay_buffer.ReplayBuffer object at 0x107c66c40>\":\t{\n",
      "\"act_buf\":\t\"[0. 0. 0. ... 0. 0. 0.]\",\n",
      "\"adv_buf\":\t\"[0. 0. 0. ... 0. 0. 0.]\",\n",
      "\"capacity\":\t1000000,\n",
      "\"gamma\":\t0.9800000190734863,\n",
      "\"lam\":\t0.9700000286102295,\n",
      "\"logp_buf\":\t\"[0. 0. 0. ... 0. 0. 0.]\",\n",
      "\"mask_buf\":\t\"[[0. 0.]\\n [0. 0.]\\n [0. 0.]\\n ...\\n [0. 0.]\\n [0. 0.]\\n [0. 0.]]\",\n",
      "\"max_size\":\t1000000,\n",
      "\"obs_buf\":\t\"[[0. 0. 0. 0.]\\n [0. 0. 0. 0.]\\n [0. 0. 0. 0.]\\n ...\\n [0. 0. 0. 0.]\\n [0. 0. 0. 0.]\\n [0. 0. 0. 0.]]\",\n",
      "\"path_start_idx\":\t0,\n",
      "\"ptr\":\t0,\n",
      "\"ret_buf\":\t\"[0. 0. 0. ... 0. 0. 0.]\",\n",
      "\"rew_buf\":\t\"[0. 0. 0. ... 0. 0. 0.]\",\n",
      "\"with_vf_baseline\":\tfalse\n",
      "}\n",
      "},\n",
      "\"_seed\":\t1,\n",
      "\"_train_vf_iters\":\t80,\n",
      "\"_traj_per_epoch\":\t8,\n",
      "\"_vf_lr\":\t0.0010000000474974513,\n",
      "\"_with_vf_baseline\":\tfalse,\n",
      "\"logger\":\t{\n",
      "\"<utils.logger.EpochLogger object at 0x15db649d0>\":\t{\n",
      "\"epoch_dict\":\t{},\n",
      "\"exp_name\":\t\"relayrl-reinforce-info\",\n",
      "\"first_row\":\ttrue,\n",
      "\"log_current_row\":\t{},\n",
      "\"log_headers\":\t[],\n",
      "\"output_dir\":\t\"././logs/relayrl-reinforce-info/relayrl-reinforce-info_s388090001\",\n",
      "\"output_file\":\t{\n",
      "\"<_io.TextIOWrapper name='././logs/relayrl-reinforce-info/relayrl-reinforce-info_s388090001/progress.txt' mode='w' encoding='UTF-8'>\":\t{\n",
      "\"mode\":\t\"w\"\n",
      "}\n",
      "}\n",
      "}\n",
      "},\n",
      "\"save_model_path\":\t\"/Users/tybg/Documents/GitHub/RelayRL-prototype/examples/cartpole/server_model.pt\"\n",
      "}\n",
      "}\n",
      "}\n",
      "[REINFORCE Algorithm] Initialized\n",
      "[TrainingServer - new] Learning algorithm status acquired: true\n",
      "[TrainingServer - listen_for_agents] Listening for agent requests via ROUTER-DEALER...\n",
      "[TrainingServer - training_loop] Starting training loop\n",
      "[TrainingServer - training_loop] Binding to trajectory server: tcp://127.0.0.1:7776\n",
      "[TrainingServer - listen_for_agents] Binding to tcp://127.0.0.1:7777\n",
      "[Instantiating RelayRL-Framework Agent...]\n",
      "[ConfigLoader - load_config] Found config.json in current directory: \"relayrl_config.json\"\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLAgent - new] Waiting for initial model at \"tcp://127.0.0.1:50051\"\n",
      "[RelayRLAgent - new] Requesting initial model...\n",
      "[TrainingServer - listen_for_agents] Received request: (AGENT_ID-3879975::GET_MODEL)\n",
      "[TrainingServer - listen_for_agents] Responding to model request...\n",
      "[TrainingServer - listen_for_agents] Sending model file...\n",
      "[RelayRLAgent - new] Received the initial model\n",
      "[TrainingServer - listen_for_agents] Received request: (AGENT_ID-3879975::MODEL_SET)\n",
      "[RelayRLAgent - new] Received reply: (TrainingServer::ID_LOGGED)\n",
      "[RelayRLAgent - new] Starting thread to listen for updated models\n",
      "[RelayRLAgent - loop_for_updated_model] Starting loop for updated model\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[TrainingServer - training_loop] Received trajectory #1\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "#### Episode 1: Total Reward = 13.0 ####\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "#### Episode 2: Total Reward = 11.0 ####\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "#### Episode 3: Total Reward = 14.0 ####\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "#### Episode 4: Total Reward = 10.0 ####\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hs/4571y2pn0m1dzbk3qbqdzp680000gn/T/ipykernel_38799/1290235033.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  action_value = int(action_obj.get_act())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "#### Episode 5: Total Reward = 18.0 ####\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "#### Episode 6: Total Reward = 16.0 ####\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "#### Episode 7: Total Reward = 15.0 ####\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "#### Episode 8: Total Reward = 32.0 ####\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[TrainingServer - training_loop] Received trajectory #2\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "#### Episode 9: Total Reward = 33.0 ####\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "[RelayRLTrajectory - action_done] Sending to TrainingServer\n",
      "#### Episode 10: Total Reward = 12.0 ####\n",
      "[TrainingServer - training_loop] Received trajectory #3\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TrainingServer - training_loop] Received trajectory #4\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #5\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #6\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #7\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #8\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |               1 |\n",
      "|    AverageEpRet |            5.67 |\n",
      "|        StdEpRet |            3.94 |\n",
      "|        MaxEpRet |              15 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            6.67 |\n",
      "|          LossPi |          0.0582 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |               0 |\n",
      "|         Entropy |         -0.0656 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[TrainingServer - training_loop] Received trajectory #9\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #10\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #11\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #12\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #13\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #14\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #15\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #16\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |               2 |\n",
      "|    AverageEpRet |            12.9 |\n",
      "|        StdEpRet |            7.76 |\n",
      "|        MaxEpRet |              30 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            13.9 |\n",
      "|          LossPi |          0.0318 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |        -0.00985 |\n",
      "|         Entropy |         -0.0851 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #17\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #18\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #19\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #20\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #21\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #22\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #23\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #24\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |               3 |\n",
      "|    AverageEpRet |            20.4 |\n",
      "|        StdEpRet |            11.9 |\n",
      "|        MaxEpRet |              46 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            21.8 |\n",
      "|          LossPi |          0.0226 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0122 |\n",
      "|         Entropy |         -0.0694 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #25\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #26\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #27\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #28\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #29\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #30\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #31\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #32\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |               4 |\n",
      "|    AverageEpRet |              28 |\n",
      "|        StdEpRet |            16.1 |\n",
      "|        MaxEpRet |              61 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            29.7 |\n",
      "|          LossPi |          0.0196 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0126 |\n",
      "|         Entropy |         -0.0587 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #33\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #34\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #35\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #36\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #37\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #38\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #39\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #40\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |               5 |\n",
      "|    AverageEpRet |            35.6 |\n",
      "|        StdEpRet |            20.5 |\n",
      "|        MaxEpRet |              76 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            37.6 |\n",
      "|          LossPi |          0.0151 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0166 |\n",
      "|         Entropy |         -0.0535 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #41\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #42\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #43\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #44\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #45\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #46\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #47\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #48\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |               6 |\n",
      "|    AverageEpRet |            43.3 |\n",
      "|        StdEpRet |            24.9 |\n",
      "|        MaxEpRet |              92 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            45.6 |\n",
      "|          LossPi |          0.0106 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0157 |\n",
      "|         Entropy |         -0.0524 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #49\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #50\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #51\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #52\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #53\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #54\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #55\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #56\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |               7 |\n",
      "|    AverageEpRet |            50.9 |\n",
      "|        StdEpRet |            29.2 |\n",
      "|        MaxEpRet |             107 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            53.6 |\n",
      "|          LossPi |         0.00669 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0198 |\n",
      "|         Entropy |         -0.0553 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #57\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #58\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #59\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #60\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #61\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #62\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #63\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #64\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |               8 |\n",
      "|    AverageEpRet |            58.6 |\n",
      "|        StdEpRet |            33.7 |\n",
      "|        MaxEpRet |             123 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            61.6 |\n",
      "|          LossPi |         0.00209 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0201 |\n",
      "|         Entropy |         -0.0589 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #65\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #66\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #67\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #68\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #69\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #70\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #71\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #72\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |               9 |\n",
      "|    AverageEpRet |            66.3 |\n",
      "|        StdEpRet |            38.2 |\n",
      "|        MaxEpRet |             138 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            69.6 |\n",
      "|          LossPi |        -0.00183 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0245 |\n",
      "|         Entropy |         -0.0635 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #73\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #74\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #75\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #76\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #77\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #78\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #79\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #80\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              10 |\n",
      "|    AverageEpRet |              74 |\n",
      "|        StdEpRet |            42.6 |\n",
      "|        MaxEpRet |             154 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            77.6 |\n",
      "|          LossPi |        -0.00563 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0295 |\n",
      "|         Entropy |         -0.0687 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[TrainingServer - training_loop] Received trajectory #81\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #82\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #83\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #84\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #85\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #86\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #87\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #88\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              11 |\n",
      "|    AverageEpRet |            81.8 |\n",
      "|        StdEpRet |            47.1 |\n",
      "|        MaxEpRet |             169 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            85.6 |\n",
      "|          LossPi |        -0.00965 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0341 |\n",
      "|         Entropy |         -0.0751 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[TrainingServer - training_loop] Received trajectory #89\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #90\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #91\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #92\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #93\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #94\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #95\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #96\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              12 |\n",
      "|    AverageEpRet |            89.5 |\n",
      "|        StdEpRet |            51.6 |\n",
      "|        MaxEpRet |             185 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |            93.6 |\n",
      "|          LossPi |         -0.0134 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0415 |\n",
      "|         Entropy |         -0.0819 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #97\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #98\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #99\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #100\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #101\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #102\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #103\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #104\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              13 |\n",
      "|    AverageEpRet |            97.2 |\n",
      "|        StdEpRet |            56.1 |\n",
      "|        MaxEpRet |             200 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |             102 |\n",
      "|          LossPi |         -0.0154 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0498 |\n",
      "|         Entropy |          -0.089 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #105\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #106\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #107\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #108\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #109\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #110\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #111\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #112\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              14 |\n",
      "|    AverageEpRet |             105 |\n",
      "|        StdEpRet |            60.5 |\n",
      "|        MaxEpRet |             216 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |             110 |\n",
      "|          LossPi |          -0.018 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0528 |\n",
      "|         Entropy |         -0.0969 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #113\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #114\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #115\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #116\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #117\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #118\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #119\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #120\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              15 |\n",
      "|    AverageEpRet |             113 |\n",
      "|        StdEpRet |            65.1 |\n",
      "|        MaxEpRet |             232 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |             118 |\n",
      "|          LossPi |         -0.0198 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0534 |\n",
      "|         Entropy |          -0.104 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #121\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #122\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #123\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #124\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #125\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #126\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #127\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #128\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              16 |\n",
      "|    AverageEpRet |             120 |\n",
      "|        StdEpRet |            69.6 |\n",
      "|        MaxEpRet |             248 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |             126 |\n",
      "|          LossPi |         -0.0228 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0644 |\n",
      "|         Entropy |          -0.113 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[TrainingServer - training_loop] Received trajectory #129\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #130\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #131\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #132\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #133\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #134\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #135\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #136\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              17 |\n",
      "|    AverageEpRet |             128 |\n",
      "|        StdEpRet |            74.2 |\n",
      "|        MaxEpRet |             263 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |             134 |\n",
      "|          LossPi |         -0.0267 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0694 |\n",
      "|         Entropy |          -0.123 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #137\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #138\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #139\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #140\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #141\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #142\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #143\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #144\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              18 |\n",
      "|    AverageEpRet |             136 |\n",
      "|        StdEpRet |            78.7 |\n",
      "|        MaxEpRet |             279 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |             142 |\n",
      "|          LossPi |         -0.0287 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0744 |\n",
      "|         Entropy |          -0.129 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #145\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #146\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #147\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #148\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #149\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #150\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #151\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #152\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              19 |\n",
      "|    AverageEpRet |             144 |\n",
      "|        StdEpRet |            83.3 |\n",
      "|        MaxEpRet |             295 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |             150 |\n",
      "|          LossPi |         -0.0302 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |          -0.078 |\n",
      "|         Entropy |          -0.134 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[TrainingServer - training_loop] Received trajectory #153\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #154\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #155\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #156\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #157\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #158\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #159\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #160\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              20 |\n",
      "|    AverageEpRet |             152 |\n",
      "|        StdEpRet |            87.9 |\n",
      "|        MaxEpRet |             311 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |             158 |\n",
      "|          LossPi |         -0.0314 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0803 |\n",
      "|         Entropy |           -0.14 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[TrainingServer - training_loop] Received trajectory #161\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #162\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #163\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #164\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #165\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #166\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #167\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #168\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "-------------------------------------\n",
      "|           Epoch |              21 |\n",
      "|    AverageEpRet |             160 |\n",
      "|        StdEpRet |            92.4 |\n",
      "|        MaxEpRet |             326 |\n",
      "|        MinEpRet |               1 |\n",
      "|           EpLen |             166 |\n",
      "|          LossPi |         -0.0313 |\n",
      "|     DeltaLossPi |               0 |\n",
      "|              KL |         -0.0878 |\n",
      "|         Entropy |          -0.149 |\n",
      "-------------------------------------\n",
      "[TrainingServer - send_ongoing_model] Preparing to send new model to RelayRLAgent\n",
      "[TrainingServer - send_ongoing_model] Model sent\n",
      "[RelayRLAgent - loop_for_updated_model] Receives the model\n",
      "[TrainingServer - training_loop] Received trajectory #169\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLAgent - loop_for_updated_model] Model updated\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #170\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #171\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #172\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #173\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Received trajectory #174\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[RelayRLTrajectory] New 1000 length trajectory created\n",
      "[TrainingServer - training_loop] Waiting for new trajectory...\n",
      "[TrainingServer - training_loop] No trajectory received\n",
      "[TrainingServer - training_loop] Waiting for new trajectory...\n",
      "[TrainingServer - training_loop] No trajectory received\n",
      "[TrainingServer - training_loop] Waiting for new trajectory...\n",
      "[TrainingServer - training_loop] No trajectory received\n",
      "[TrainingServer - training_loop] Waiting for new trajectory...\n",
      "[TrainingServer - training_loop] No trajectory received\n",
      "[TrainingServer - training_loop] Waiting for new trajectory...\n",
      "[TrainingServer - training_loop] No trajectory received\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
